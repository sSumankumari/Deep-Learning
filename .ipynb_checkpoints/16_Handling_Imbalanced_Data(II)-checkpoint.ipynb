{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1650a26e",
   "metadata": {},
   "source": [
    "# Handling Imbalanced Data for Bank Customer Churn Prediction\n",
    "Customer churn prediction is to measure why customers are leaving a business. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146f97d0",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d3f8b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9b3e536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8940</th>\n",
       "      <td>8941</td>\n",
       "      <td>15658148</td>\n",
       "      <td>Udokamma</td>\n",
       "      <td>657</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>185827.74</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>1216</td>\n",
       "      <td>15625080</td>\n",
       "      <td>Parkin</td>\n",
       "      <td>745</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>54</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>173912.29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6275</th>\n",
       "      <td>6276</td>\n",
       "      <td>15814940</td>\n",
       "      <td>Lawrence</td>\n",
       "      <td>642</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>33</td>\n",
       "      <td>9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>150475.14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8431</th>\n",
       "      <td>8432</td>\n",
       "      <td>15586752</td>\n",
       "      <td>Parkes</td>\n",
       "      <td>628</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>33</td>\n",
       "      <td>8</td>\n",
       "      <td>152143.89</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32174.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6886</th>\n",
       "      <td>6887</td>\n",
       "      <td>15670738</td>\n",
       "      <td>Mazzanti</td>\n",
       "      <td>733</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>113939.36</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3218.71</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "8940       8941    15658148  Udokamma          657    France    Male   38   \n",
       "1215       1216    15625080    Parkin          745     Spain  Female   54   \n",
       "6275       6276    15814940  Lawrence          642     Spain  Female   33   \n",
       "8431       8432    15586752    Parkes          628   Germany    Male   33   \n",
       "6886       6887    15670738  Mazzanti          733   Germany    Male   45   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "8940       7       0.00              2          1               0   \n",
       "1215       8       0.00              1          1               0   \n",
       "6275       9       0.00              2          1               1   \n",
       "8431       8  152143.89              1          1               1   \n",
       "6886       2  113939.36              2          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "8940        185827.74       0  \n",
       "1215        173912.29       1  \n",
       "6275        150475.14       0  \n",
       "8431         32174.03       0  \n",
       "6886          3218.71       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Bank_Churn_Modelling.csv\")\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b75720",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0045d836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop RowNumber & CustomerID column (it is of no use)\n",
    "df.drop(['RowNumber', 'Surname', 'CustomerId'], axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ef8d935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore          int64\n",
       "Geography           object\n",
       "Gender              object\n",
       "Age                  int64\n",
       "Tenure               int64\n",
       "Balance            float64\n",
       "NumOfProducts        int64\n",
       "HasCrCard            int64\n",
       "IsActiveMember       int64\n",
       "EstimatedSalary    float64\n",
       "Exited               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08f0b889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>822</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10062.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>501</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>142051.07</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74940.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>644</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "      <td>155060.41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29179.52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>800</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>167773.55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7963 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "1             608     Spain  Female   41       1   83807.86              1   \n",
       "3             699    France  Female   39       1       0.00              2   \n",
       "4             850     Spain  Female   43       2  125510.82              1   \n",
       "6             822    France    Male   50       7       0.00              2   \n",
       "8             501    France    Male   44       4  142051.07              2   \n",
       "...           ...       ...     ...  ...     ...        ...            ...   \n",
       "9993          644    France    Male   28       7  155060.41              1   \n",
       "9994          800    France  Female   29       2       0.00              2   \n",
       "9995          771    France    Male   39       5       0.00              2   \n",
       "9996          516    France    Male   35      10   57369.61              1   \n",
       "9999          792    France  Female   28       4  130142.79              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "1             0               1        112542.58       0  \n",
       "3             0               0         93826.63       0  \n",
       "4             1               1         79084.10       0  \n",
       "6             1               1         10062.80       0  \n",
       "8             0               1         74940.50       0  \n",
       "...         ...             ...              ...     ...  \n",
       "9993          1               0         29179.52       0  \n",
       "9994          0               0        167773.55       0  \n",
       "9995          1               0         96270.64       0  \n",
       "9996          1               1        101699.77       0  \n",
       "9999          1               0         38190.78       0  \n",
       "\n",
       "[7963 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Exited'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9003c243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a25e2edf00>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAHFCAYAAAAT5Oa6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAABSIUlEQVR4nO3deVhUZf8/8PfIMiwiyDqgiKikKKIIamoJpoILmvkUGuaKS7kiLkimgiUkpvmES6mlprn0lFqWG+75dUMSV9I03BLCFEERAeH+/dHF+TUOKKOzIOf9uq65Luc+99znc2bAeXOfTSGEECAiIiKSsRrGLoCIiIjI2BiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIjIKE6fPo2hQ4fC09MTFhYWqFmzJlq1aoXExETcuXNHL+vctm0bYmNj9TJ2VfHXX39h2rRpaN68OWrWrAkLCwt4eXlhwoQJ+P3336V+Q4YMQc2aNY1YaeVduXIFCoVCetSoUQMODg7o0aMHjhw5YpAahgwZgvr166u1KRQKrX+ebt68idjYWKSlpWksi42NhUKhePYin8GpU6egUCgwbdq0Cvv8/vvvUCgUGD9+PACgfv36GDJkiIEqrFh5n4k+a3vw4AFiY2Oxf/9+jWWrVq2CQqHAlStX9LJuMgxTYxdA8rN8+XKMHj0ajRs3xpQpU9C0aVMUFxfjxIkT+Pzzz3HkyBFs3rxZ5+vdtm0bFi9eXG1D0fHjxxEaGgohBMaOHYt27drB3NwcFy5cwNq1a9GmTRvk5OQYu8xnNm7cOISHh6OkpATnzp1DXFwcOnXqhCNHjsDPz8/g9Rw5cgR169bV6jU3b95EXFwc6tevj5YtW6otGz58OLp166bDCp+uRYsW8Pf3x9dff405c+bAxMREo8/KlSsBABEREQCAzZs3o1atWgats7L0WduDBw8QFxcHAAgKClJb1rNnTxw5cgSurq56WTcZBgMRGdSRI0fw3nvvoWvXrtiyZQuUSqW0rGvXrpg0aRJ27NhhxAqrroKCAlhYWJQ7i5CXl4fXX38dFhYWOHz4sNoXdVBQEEaNGoXvvvvOkOUC+OdLxMrKSidj1atXDy+//DIAoEOHDmjUqBE6d+6MJUuWYPny5eW+5knv2fMqq0VX6tatq3XA0oWIiAiMHj0a27dvR2hoqNqykpISfP311/D390eLFi0AwCjhs7KMVZuTkxOcnJyMsm7SHe4yI4OKj4+HQqHAsmXL1MJQGXNzc/Tu3Vt6XtFuicenxh88eIDJkydLu+Ds7e0REBCA9evXA/hnen3x4sXSmGWPsinuhw8fIiYmBp6enjA3N0edOnUwZswY3L17V2O9oaGh+Omnn+Dn5wdLS0t4e3vjp59+AvDP1Lm3tzesra3Rpk0bnDhxQqP2EydOoHfv3rC3t4eFhQX8/Pzw7bffqvUpm4LftWsXhg0bBicnJ1hZWaGwsLDc93X58uXIyspCYmJihV+qb775pkbbpUuX0KNHD9SsWRPu7u6YNGmS2jr2798PhUKhsZugbDfWqlWrpLay3XBnzpxBcHAwbGxs0LlzZ+k9Hzt2LNasWQNvb29YWVmhRYsW0vv2LMoCydWrVwE8/T3buHEj2rVrB2tra9SsWRMhISE4efKkxrirVq1C48aNoVQq4e3tja+//rrc9Zf3s/nnn39i5MiRcHd3h7m5Odzc3PDmm2/ir7/+wv79+9G6dWsAwNChQ6WfwbIxyttlVlpaisTERDRp0gRKpRLOzs4YNGgQbty4odYvKCgIPj4+SElJwauvvgorKys0aNAAH3/8MUpLS5/4PoaHh8PS0lKaCfq3Xbt24c8//8SwYcOktsd/90pLS/HRRx+hcePGsLS0hJ2dHXx9ffHf//5X6lPe7q2Ktnnx4sXo2LEjnJ2dYW1tjebNmyMxMRHFxcVP3I7yagsKClL7ff/3o+xn99atWxg9ejSaNm2KmjVrwtnZGa+99hp++eUXaZwrV65IgScuLk4ao2xdFe0y++qrr9CiRQvp/6Q33ngD6enpan3Kfm+e9rtI+scZIjKYkpIS7N27F/7+/nB3d9fp2FFRUVizZg0++ugj+Pn5IT8/H2fPnsXt27cBADNmzEB+fj6+++47teNOXF1dIYRAnz59sGfPHsTExODVV1/F6dOnMWvWLBw5cgRHjhxRC2+nTp1CTEwMpk+fDltbW8TFxaFv376IiYnBnj17pNAXHR2N0NBQZGRkwNLSEgCwb98+dOvWDW3btsXnn38OW1tbbNiwAf369cODBw80jn8YNmwYevbsiTVr1iA/Px9mZmblbv+uXbtgYmKCXr16Vfo9Ky4uRu/evREREYFJkybh4MGD+PDDD2Fra4uZM2dWepx/KyoqQu/evTFq1ChMmzYNjx49kpb9/PPPSElJwezZs1GzZk0kJibijTfewIULF9CgQQOt13Xp0iUA0PjLvLz3LD4+Hh988AGGDh2KDz74AEVFRZg3bx5effVVHD9+HE2bNgXwzxfb0KFD8frrr2P+/PnIzc1FbGwsCgsLUaPGk/9+/PPPP9G6dWsUFxfj/fffh6+vL27fvo2dO3ciJycHrVq1wsqVK6UaevbsCQBPnBV67733sGzZMowdOxahoaG4cuUKZsyYgf379+PXX3+Fo6Oj1DcrKwsDBgzApEmTMGvWLGzevBkxMTFwc3PDoEGDKlyHra0t/vOf/2Djxo24deuW2vu5cuVKWFhYIDw8vMLXJyYmIjY2Fh988AE6duyI4uJi/Pbbbxp/TFTW5cuXER4eLv1xcurUKcyZMwe//fYbvvrqK63GWrJkCfLy8tTaZsyYgX379qFx48YAIB2zOGvWLKhUKty/fx+bN29GUFAQ9uzZg6CgILi6umLHjh3o1q0bIiIiMHz4cACaP3v/lpCQgPfffx9vv/02EhIScPv2bcTGxqJdu3ZISUmBl5eX1Fcfv4v0DASRgWRlZQkAon///pV+DQAxa9YsjXYPDw8xePBg6bmPj4/o06fPE8caM2aMKO9HfseOHQKASExMVGvfuHGjACCWLVumtl5LS0tx48YNqS0tLU0AEK6uriI/P19q37JliwAgfvzxR6mtSZMmws/PTxQXF6utKzQ0VLi6uoqSkhIhhBArV64UAMSgQYOeuE3/HlelUlWqrxBCDB48WAAQ3377rVp7jx49ROPGjaXn+/btEwDEvn371PplZGQIAGLlypUaY3711Vca6wMgXFxcRF5entSWlZUlatSoIRISEp5Ya9m65s6dK4qLi8XDhw9FamqqaN26tQAgfv75ZyFExe/ZtWvXhKmpqRg3bpxa+71794RKpRJhYWFCCCFKSkqEm5ubaNWqlSgtLZX6XblyRZiZmQkPDw+Nbfr3z+awYcOEmZmZOH/+fIXbkpKSovG+lZk1a5baz2d6eroAIEaPHq3W79ixYwKAeP/996W2wMBAAUAcO3ZMrW/Tpk1FSEhIhfWUKfucFyxYILXdvn1bKJVKMWDAALW+j//uhYaGipYtWz5x/MGDB2u8f0JobvPjSkpKRHFxsfj666+FiYmJuHPnzhPHfLy2x82bN0/jd/pxjx49EsXFxaJz587ijTfekNpv3bpV4f9HZT97GRkZQgghcnJyhKWlpejRo4dav2vXrgmlUinCw8PVtqMyv4ukf9xlRtVCmzZtsH37dkybNg379+9HQUFBpV+7d+9eANCYnXnrrbdgbW2NPXv2qLW3bNkSderUkZ57e3sD+Gd6/t/Hy5S1l+3SuXTpEn777TcMGDAAAPDo0SPp0aNHD2RmZuLChQtq6/rPf/5T6e3QlkKh0JhR8vX1lep9VhXV3KlTJ9jY2EjPXVxc4OzsXOn1RUdHw8zMDBYWFvD398e1a9fwxRdfoEePHk9c/86dO/Ho0SMMGjRI7T23sLBAYGCgtDvwwoULuHnzJsLDw9V243h4eKB9+/ZPrW/79u3o1KmT9Lk/r3379gHQ/Lls06YNvL29NX4uVSoV2rRpo9ZW2c8zMDAQDRs2VNtt9s0336CwsFBtd1l52rRpg1OnTmH06NHYuXOnxoyMtk6ePInevXvDwcEBJiYmMDMzw6BBg1BSUoKLFy8+87jr16/H1KlT8cEHH2DEiBFqyz7//HO0atUKFhYWMDU1hZmZGfbs2aOxe6uyjhw5goKCAo3Pzt3dHa+99prGZ6ev30XSDgMRGYyjoyOsrKyQkZGh87E/++wzREdHY8uWLejUqRPs7e3Rp08ftVPNK3L79m2YmppqTH8rFAqoVCppt1sZe3t7tefm5uZPbH/48CGAf06JB4DJkyfDzMxM7TF69GgAwN9//602RmXPWqlXrx5u3bqF/Pz8SvUHACsrK1hYWKi1KZVKqd5nYWVlVeFZPg4ODhptSqWy0uF1woQJSElJQWpqKi5fvozMzEyMHDlSo9/j71nZ+966dWuN933jxo3Se172OatUKo0xy2t73K1bt3R6UHRZPeX9DLi5uWn8XD7P+6tQKDBs2DCcOXNGOu5t5cqV8PT0RKdOnZ742piYGHzyySc4evQounfvDgcHB3Tu3Lnc4+ee5tq1a3j11Vfx559/4r///S9++eUXpKSkSMf/afOHzr/t27cPQ4YMwaBBg/Dhhx+qLVuwYAHee+89tG3bFt9//z2OHj2KlJQUdOvW7ZnXp+1np4/fRdIejyEigzExMUHnzp2xfft23Lhxo1JfHkqlstwDCx//D8Xa2hpxcXGIi4vDX3/9Jc0W9erVC7/99tsT1+Hg4IBHjx5pHD8hhEBWVpZ0IOzzKjveIyYmBn379i23T9lxDWUqe3ZUSEgIdu3aha1bt6J///7PV+i/lP0n/fhn8HhwK6PP6+jUrVsXAQEBT+33eA1l7/t3330HDw+PCl9XFiiysrI0lpXX9jgnJyeNg52fR1k9mZmZGr8rN2/eVDt+SBeGDBmCmTNn4quvvoKZmRlOnjyJDz/88KmfqampKaKiohAVFYW7d+9i9+7deP/99xESEoLr169LX/bl/R4//nO0ZcsW5OfnY9OmTWqfVXnXbaqs06dPo0+fPggMDCz3bMS1a9ciKCgIS5cuVWu/d+/eM6/z35/d4/Tx2ZFucIaIDComJgZCCIwYMQJFRUUay4uLi7F161bpef369XH69Gm1Pnv37sX9+/crXIeLiwuGDBmCt99+GxcuXMCDBw8AQDow+vG/+srOhFq7dq1a+/fff4/8/Hxp+fNq3LgxvLy8cOrUKQQEBJT7+PcuJW1ERERApVJh6tSp+PPPP8vts2nTJq3HLTsz6PHP4Mcff9R6LGMJCQmBqakpLl++XOH7Dvzz+bi6umL9+vUQQkivv3r1Kg4fPvzU9XTv3h379u3T2O35bxX9DJbntddeA6D5c5mSkoL09HSd/VyWcXNzQ7du3bB+/XosXrwYNWrUwODBg7Uaw87ODm+++SbGjBmDO3fuSGdd1a9fH9nZ2dJsHfDPAfg7d+5Ue31Z+Pr3SQxCiAovq/A0165dQ/fu3dGgQQN8//335Z6UoFAoNM54PX36tMZFP7X57Nq1awdLS0uNz+7GjRvYu3evzj870g3OEJFBtWvXDkuXLsXo0aPh7++P9957D82aNUNxcTFOnjyJZcuWwcfHR9qfPnDgQMyYMQMzZ85EYGAgzp8/j0WLFsHW1lZt3LZt2yI0NBS+vr6oXbs20tPTsWbNGrRr1046rqd58+YAgLlz56J79+4wMTGBr68vunbtipCQEERHRyMvLw8dOnSQzjLz8/PDwIEDdbb9X3zxBbp3746QkBAMGTIEderUwZ07d5Ceno5ff/0V//vf/55pXFtbW/zwww8IDQ2Fn5+f2oUZf//9d6xduxanTp2qcGaqIiqVCl26dEFCQgJq164NDw8P7Nmz55nClbHUr18fs2fPxvTp0/HHH3+gW7duqF27Nv766y8cP35cml2sUaMGPvzwQwwfPhxvvPEGRowYgbt37yI2NrZSu8xmz56N7du3o2PHjnj//ffRvHlz3L17Fzt27EBUVBSaNGmChg0bwtLSEt988w28vb1Rs2ZNuLm5wc3NTWO8xo0bY+TIkUhKSkKNGjXQvXt36Swzd3d3TJw4UefvVUREBH7++WesWLECISEhlTobtFevXvDx8UFAQACcnJxw9epVLFy4EB4eHtKZVP369cPMmTPRv39/TJkyBQ8fPsRnn32GkpIStbG6du0Kc3NzvP3225g6dSoePnyIpUuXPvMFRbt37467d+9i0aJFOHfunNqyhg0bwsnJCaGhofjwww8xa9YsBAYG4sKFC5g9ezY8PT3VzpK0sbGBh4cHfvjhB3Tu3Bn29vZwdHQs93ICdnZ2mDFjBt5//30MGjQIb7/9Nm7fvo24uDhYWFhg1qxZz7Q9pGfGPaab5CotLU0MHjxY1KtXT5ibmwtra2vh5+cnZs6cKbKzs6V+hYWFYurUqcLd3V1YWlqKwMBAkZaWpnE2ybRp00RAQICoXbu2UCqVokGDBmLixIni77//Vhtr+PDhwsnJSSgUCrWzQgoKCkR0dLTw8PAQZmZmwtXVVbz33nsiJydHrW4PDw/Rs2dPje0BIMaMGaPWVnZ21Lx589TaT506JcLCwoSzs7MwMzMTKpVKvPbaa+Lzzz+X+pSdtZKSkqLV+5qVlSWio6NFs2bNhJWVlVAqlaJRo0Zi1KhR4syZM1K/wYMHC2tra43Xl3fWT2ZmpnjzzTeFvb29sLW1Fe+88444ceJEuWeZlTemEOW/P0I8/awgISp+Hx/3tPdsy5YtolOnTqJWrVpCqVQKDw8P8eabb4rdu3er9VuxYoXw8vIS5ubm4qWXXhJfffVVuWc0oZwzjq5fvy6GDRsmVCqVMDMzE25ubiIsLEz89ddfUp/169eLJk2aCDMzM7UxynvvS0pKxNy5c8VLL70kzMzMhKOjo3jnnXfE9evX1foFBgaKZs2aaWxzRWd3VaSoqEi4uLiUe9ZTmcc/s/nz54v27dsLR0dHYW5uLurVqyciIiLElStX1F63bds20bJlS2FpaSkaNGggFi1aVO42b926VbRo0UJYWFiIOnXqiClTpojt27drnO1YmbPMAFT4KPvZLSwsFJMnTxZ16tQRFhYWolWrVmLLli3ljr97927h5+cnlEqlACCt6/GzzMqsWLFC+Pr6CnNzc2Fraytef/11ce7cObU+2vwukn4phPjX3DARERGRDPEYIiIiIpI9BiIiIiKSPQYiIiIikj0GIiIiIpI9BiIiIiKSPQYiIiIikj1emLGSSktLcfPmTdjY2Oj19gRERESkO0II3Lt3D25ubqhRo+J5IAaiSrp582alrtpKREREVc/169efeA9NowaigwcPYt68eUhNTUVmZiY2b96MPn36APjnnlYffPABtm3bhj/++AO2trbo0qULPv74Y7XL3BcWFmLy5MlYv349CgoK0LlzZyxZskRto3NycjB+/Hjp/ku9e/dGUlIS7OzsKl1r2T2mrl+/XuHdvImIiKhqycvLg7u7+1PvFWnUQJSfn48WLVpg6NCh+M9//qO27MGDB/j1118xY8YMtGjRAjk5OYiMjETv3r1x4sQJqV9kZCS2bt2KDRs2wMHBAZMmTUJoaChSU1NhYmICAAgPD8eNGzewY8cOAMDIkSMxcOBAtZuIPk3ZbrJatWoxEBEREb1gnna4S5W5dYdCoVCbISpPSkoK2rRpg6tXr6JevXrIzc2Fk5MT1qxZg379+gH4/7u2tm3bhpCQEKSnp6Np06Y4evQo2rZtCwA4evQo2rVrh99++w2NGzeuVH15eXmwtbVFbm4uAxEREdELorLf3y/UWWa5ublQKBTSrq7U1FQUFxcjODhY6uPm5gYfHx8cPnwYAHDkyBHY2tpKYQgAXn75Zdja2kp9iIiISN5emIOqHz58iGnTpiE8PFxKeFlZWTA3N0ft2rXV+rq4uCArK0vq4+zsrDGes7Oz1Kc8hYWFKCwslJ7n5eXpYjOIiIioCnohAlFxcTH69++P0tJSLFmy5Kn9hRBq+wrL22/4eJ/HJSQkIC4uTutaS0pKUFxcrPXryLjMzMykY86IiEh+qnwgKi4uRlhYGDIyMrB37161/X8qlQpFRUXIyclRmyXKzs5G+/btpT5//fWXxri3bt2Ci4tLheuNiYlBVFSU9LzsKPWKCCGQlZWFu3fvarN5VIXY2dlBpVLxOlNERDJUpQNRWRj6/fffsW/fPjg4OKgt9/f3h5mZGZKTkxEWFgYAyMzMxNmzZ5GYmAgAaNeuHXJzc3H8+HG0adMGAHDs2DHk5uZKoak8SqUSSqWy0rWWhSFnZ2dYWVnxS/UFIoTAgwcPkJ2dDQBwdXU1ckVERGRoRg1E9+/fx6VLl6TnGRkZSEtLg729Pdzc3PDmm2/i119/xU8//YSSkhLpmB97e3uYm5vD1tYWERERmDRpEhwcHGBvb4/JkyejefPm6NKlCwDA29sb3bp1w4gRI/DFF18A+Oe0+9DQ0EqfYfY0JSUlUhh6PLTRi8HS0hLAP7OLzs7O3H1GRCQzRg1EJ06cQKdOnaTnZbuoBg8ejNjYWOlCii1btlR73b59+xAUFAQA+PTTT2FqaoqwsDDpwoyrVq1S+0L75ptvMH78eOlstN69e2PRokU6246yY4asrKx0NiYZXtnnV1xczEBERCQzVeY6RFXdk65j8PDhQ2RkZMDT0xMWFhZGqpCeFz9HIqLqp1peh4iIiIhIHxiI6LkEBQUhMjJSL2PXr18fCxcu1MvYRERE/1alzzJ70SniDHummZil/d7PIUOGYPXq1RrtISEh0r3fnmTTpk0wMzOTntevXx+RkZF6C0nauHbtGsaMGYO9e/fC0tIS4eHh+OSTT2Bubm7s0oiIqIphICJ069YNK1euVGur7CUH7O3t9VHScyspKUHPnj3h5OSEQ4cO4fbt2xg8eDCEEEhKSjJ2eUREVMVwlxlBqVRCpVKpPWrXro39+/fD3Nwcv/zyi9R3/vz5cHR0RGZmJgD1XWZBQUG4evUqJk6cCIVCoXYtpsOHD6Njx46wtLSEu7s7xo8fj/z8fGl5dnY2evXqBUtLS3h6euKbb755rm3atWsXzp8/j7Vr18LPzw9dunTB/PnzsXz5ct6GhYiINDAQUYXKws7AgQORm5uLU6dOYfr06Vi+fHm5Fy/ctGkT6tati9mzZyMzM1MKTWfOnEFISAj69u2L06dPY+PGjTh06BDGjh0rvXbIkCG4cuUK9u7di++++w5LliyRLpRYpnv37qhZs+YTH2WOHDkCHx8fuLm5SW0hISEoLCxEamqqrt8qIiJ6wXGXGeGnn35SCxMAEB0djRkzZuCjjz7C7t27MXLkSJw7dw4DBw7EG2+8Ue449vb2MDExgY2NDVQqldQ+b948hIeHSzNJXl5e+OyzzxAYGIilS5fi2rVr2L59O44ePYq2bdsCAL788kt4e3urjb9ixQoUFBRUapuysrI0bs1Su3ZtmJubP/GmvkREcqDLY1yf5fjVqoiBiNCpUycsXbpUra3s2CBzc3OsXbsWvr6+8PDweKazvlJTU3Hp0iW13WBCCJSWliIjIwMXL16EqakpAgICpOVNmjSBnZ2d2jh16tTRar3PclNfIiKSJwYigrW1NRo1alTh8sOHDwMA7ty5gzt37sDa2lqr8UtLSzFq1CiMHz9eY1m9evVw4cIFAOUHmH/r3r272vFM5bl//z6Af27qe+zYMbVlOTk5KC4ufuJNfYmISJ4YiOiJLl++jIkTJ2L58uX49ttvMWjQIOzZswc1apR/+Jm5uTlKSkrU2lq1aoVz585VGLq8vb3x6NEjnDhxQroB74ULF3D37l21ftrsMmvXrh3mzJmDzMxM6XinXbt2QalUwt/fv1JjEBGRfDAQEQoLCzWOqzE1NUXt2rUxcOBABAcHY+jQoejevTuaN2+O+fPnY8qUKeWOVb9+fRw8eBD9+/eHUqmEo6MjoqOj8fLLL2PMmDEYMWIErK2tkZ6ejuTkZCQlJaFx48bSDXiXLVsGU1NTREZGSjdcLaPNLrPg4GA0bdoUAwcOxLx583Dnzh1MnjwZI0aMeOKl24mISJ54lhlhx44dcHV1VXu88sormDNnDq5cuYJly5YB+Gc31IoVK/DBBx8gLS2t3LFmz56NK1euoGHDhnBycgIA+Pr64sCBA/j999/x6quvws/PDzNmzFA7U23lypVwd3dHYGAg+vbti5EjR8LZ2fmZt8nExAQ///wzLCws0KFDB4SFhaFPnz745JNPnnlMIiKqvnhz10rizV2rP36ORCQXcjrLjDd3JSIiIqokBiIiIiKSPQYiIiIikj0GIiIiIpI9BiIiIiKSPQYiIiIikj0GIiIiIpI9BiIiIiKSPQYiIiIikj0GInouQUFBiIyM1MvY9evXx8KFC/UyNhER0b8xEOmTQmHYxzMYMmQIFAqFxqNbt26Vev2mTZvw4YcfSs+rUoiZMGEC/P39oVQq0bJlS2OXQ0REVRjvdk/o1q0bVq5cqdamVCor9Vp7e3t9lKQTQggMGzYMx44dw+nTp41dDhERVWGcISIolUqoVCq1R+3atbF//36Ym5vjl19+kfrOnz8fjo6OyMzMBKC+yywoKAhXr17FxIkTpZmmMocPH0bHjh1haWkJd3d3jB8/Hvn5+dLy7Oxs9OrVC5aWlvD09MQ333zz3Nv12WefYcyYMWjQoMFzj0VERNUbAxFVqCzsDBw4ELm5uTh16hSmT5+O5cuXw9XVVaP/pk2bULduXcyePRuZmZlSaDpz5gxCQkLQt29fnD59Ghs3bsShQ4cwduxY6bVDhgzBlStXsHfvXnz33XdYsmQJsrOz1cbv3r07atas+cQHERHRs+AuM8JPP/2kESaio6MxY8YMfPTRR9i9ezdGjhyJc+fOYeDAgXjjjTfKHcfe3h4mJiawsbGBSqWS2ufNm4fw8HBpJsnLywufffYZAgMDsXTpUly7dg3bt2/H0aNH0bZtWwDAl19+CW9vb7XxV6xYgYKCAh1uORER0T8YiAidOnXC0qVL1drKjg0yNzfH2rVr4evrCw8Pj2c6YDo1NRWXLl1S2w0mhEBpaSkyMjJw8eJFmJqaIiAgQFrepEkT2NnZqY1Tp04drddNRERUGQxEBGtrazRq1KjC5YcPHwYA3LlzB3fu3IG1tbVW45eWlmLUqFEYP368xrJ69erhwoULAKB2zFF5unfvrnY8U3nu37+vVW1EREQAAxE9xeXLlzFx4kQsX74c3377LQYNGoQ9e/agRo3yDz8zNzdHSUmJWlurVq1w7ty5CkOXt7c3Hj16hBMnTqBNmzYAgAsXLuDu3btq/bjLjIiI9IWBiFBYWIisrCy1NlNTU9SuXRsDBw5EcHAwhg4diu7du6N58+aYP38+pkyZUu5Y9evXx8GDB9G/f38olUo4OjoiOjoaL7/8MsaMGYMRI0bA2toa6enpSE5ORlJSEho3boxu3bphxIgRWLZsGUxNTREZGQlLS0u1sbXdZXbp0iXcv38fWVlZKCgoQFpaGgCgadOmMDc312osIiKq3hiICDt27NA4a6xx48YIDw/HlStXsHXrVgCASqXCihUrEBYWhq5du5Z7scPZs2dj1KhRaNiwIQoLCyGEgK+vLw4cOIDp06fj1VdfhRACDRs2RL9+/aTXrVy5EsOHD0dgYCBcXFzw0UcfYcaMGc+1XcOHD8eBAwek535+fgCAjIwM1K9f/7nGJiKi6kUhhBDGLuJFkJeXB1tbW+Tm5qJWrVpqyx4+fIiMjAx4enrCwsLCSBXS8+LnSERyoYh7trsblEfMqtox4knf3//G6xARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQ6RCPT3+x8fMjIpIvBiIdMDMzAwA8ePDAyJXQ8yj7/Mo+TyIikg9eh0gHTExMYGdnJ92d3crK6qm3oaCqQwiBBw8eIDs7G3Z2djAxMTF2SUREZGAMRDpSdnf3slBELx47OzvpcyQiInlhINIRhUIBV1dXODs7o7i42NjlkJbMzMw4M0REJGMMRDpmYmLCL1YiIqIXDA+qJiIiItljICIiIiLZYyAiIiIi2WMgIiIiItljICIiIiLZYyAiIiIi2TNqIDp48CB69eoFNzc3KBQKbNmyRW25EAKxsbFwc3ODpaUlgoKCcO7cObU+hYWFGDduHBwdHWFtbY3evXvjxo0ban1ycnIwcOBA2NrawtbWFgMHDsTdu3f1vHVERET0ojBqIMrPz0eLFi2waNGicpcnJiZiwYIFWLRoEVJSUqBSqdC1a1fcu3dP6hMZGYnNmzdjw4YNOHToEO7fv4/Q0FCUlJRIfcLDw5GWloYdO3Zgx44dSEtLw8CBA/W+fURERPRiUIgqcotvhUKBzZs3o0+fPgD+mR1yc3NDZGQkoqOjAfwzG+Ti4oK5c+di1KhRyM3NhZOTE9asWYN+/foBAG7evAl3d3ds27YNISEhSE9PR9OmTXH06FG0bdsWAHD06FG0a9cOv/32Gxo3blyp+vLy8mBra4vc3FzUqlVL928AERGRgSjidHe/TTGrSsSIClX2+7vKHkOUkZGBrKwsBAcHS21KpRKBgYE4fPgwACA1NRXFxcVqfdzc3ODj4yP1OXLkCGxtbaUwBAAvv/wybG1tpT7lKSwsRF5entqDiIiIqqcqG4iysrIAAC4uLmrtLi4u0rKsrCyYm5ujdu3aT+zj7OysMb6zs7PUpzwJCQnSMUe2trZwd3d/ru0hIiKiqqvKBqIyCoX6tJ4QQqPtcY/3Ka//08aJiYlBbm6u9Lh+/bqWlRMREdGLosoGIpVKBQAaszjZ2dnSrJFKpUJRURFycnKe2Oevv/7SGP/WrVsas0//plQqUatWLbUHERERVU9VNhB5enpCpVIhOTlZaisqKsKBAwfQvn17AIC/vz/MzMzU+mRmZuLs2bNSn3bt2iE3NxfHjx+X+hw7dgy5ublSHyIiIpI3U2Ou/P79+7h06ZL0PCMjA2lpabC3t0e9evUQGRmJ+Ph4eHl5wcvLC/Hx8bCyskJ4eDgAwNbWFhEREZg0aRIcHBxgb2+PyZMno3nz5ujSpQsAwNvbG926dcOIESPwxRdfAABGjhyJ0NDQSp9hRkRERNWbUQPRiRMn0KlTJ+l5VFQUAGDw4MFYtWoVpk6dioKCAowePRo5OTlo27Ytdu3aBRsbG+k1n376KUxNTREWFoaCggJ07twZq1atgomJidTnm2++wfjx46Wz0Xr37l3htY+IiIhIfqrMdYiqOl6HiIiIqgteh0hTlT2GiIiIiMhQGIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2tA5EO3bswKFDh6TnixcvRsuWLREeHo6cnBydFkdERERkCKbavmDKlCmYO3cuAODMmTOYNGkSoqKisHfvXkRFRWHlypU6L5KIiKo3RZxCZ2OJWUJnY5F8aB2IMjIy0LRpUwDA999/j9DQUMTHx+PXX39Fjx49dF4gERERkb5pHYjMzc3x4MEDAMDu3bsxaNAgAIC9vT3y8vJ0Wx2RHvAvUSIiepzWgahDhw6IiopChw4dcPz4cWzcuBEAcPHiRdStW1fnBRIRERHpm9YHVS9evBhmZmb47rvvsHTpUtSpUwcAsH37dnTr1k3nBRIRERHpm1YzRI8ePcK+ffuwbNkyuLq6qi379NNPdVoYERERkaFoNUNkamqK9957D0VFRfqqh4iIiMjgtD6GqG3btjh58iQ8PDz0UQ8REdELgydpVB9aB6LRo0dj0qRJuHHjBvz9/WFtba223NfXV2fFERERERmC1oGoX79+AIDx48dLbQqFAkIIKBQKlJSU6K46IiIiIgN4pgszEhEREVUnWgciHjtERERE1c0z3e1+zZo16NChA9zc3HD16lUAwMKFC/HDDz/otLhHjx7hgw8+gKenJywtLdGgQQPMnj0bpaWlUh8hBGJjY+Hm5gZLS0sEBQXh3LlzauMUFhZi3LhxcHR0hLW1NXr37o0bN27otFYiIiJ6cWkdiJYuXYqoqCj06NEDd+/elY4ZsrOzw8KFC3Va3Ny5c/H5559j0aJFSE9PR2JiIubNm4ekpCSpT2JiIhYsWIBFixYhJSUFKpUKXbt2xb1796Q+kZGR2Lx5MzZs2IBDhw7h/v37CA0N5fFOREREBOAZAlFSUhKWL1+O6dOnw8TERGoPCAjAmTNndFrckSNH8Prrr6Nnz56oX78+3nzzTQQHB+PEiRMA/pkdWrhwIaZPn46+ffvCx8cHq1evxoMHD7Bu3ToAQG5uLr788kvMnz8fXbp0gZ+fH9auXYszZ85g9+7dOq2XiIiIXkzPdFC1n5+fRrtSqUR+fr5Oiirzyiuv4PPPP8fFixfx0ksv4dSpUzh06JA0E5WRkYGsrCwEBwer1REYGIjDhw9j1KhRSE1NRXFxsVofNzc3+Pj44PDhwwgJCSl33YWFhSgsLJSe88a1mnj9DarO+PNNJC9aByJPT0+kpaVpHFy9fft2NG3aVGeFAUB0dDRyc3PRpEkTmJiYoKSkBHPmzMHbb78NAMjKygIAuLi4qL3OxcVFOrYpKysL5ubmqF27tkafsteXJyEhAXFxcbrcHCIiIqqitA5EU6ZMwZgxY/Dw4UMIIXD8+HGsX78eCQkJWLFihU6L27hxI9auXYt169ahWbNmSEtLQ2RkJNzc3DB48GCpn0Kh/pdc2TWRnuRpfWJiYhAVFSU9z8vLg7u7+zNuCdHz44wFEZH+aB2Ihg4dikePHmHq1Kl48OABwsPDUadOHfz3v/9F//79dVrclClTMG3aNGnc5s2b4+rVq0hISMDgwYOhUqkA/DML9O+bzWZnZ0uzRiqVCkVFRcjJyVGbJcrOzkb79u0rXLdSqYRSqdTp9hAREVHV9Eyn3Y8YMQJXr15FdnY2srKycP36dUREROi6Njx48AA1aqiXaGJiIp127+npCZVKheTkZGl5UVERDhw4IIUdf39/mJmZqfXJzMzE2bNnnxiIiIiISD60niH6N0dHR13VUa5evXphzpw5qFevHpo1a4aTJ09iwYIFGDZsGIB/dpVFRkYiPj4eXl5e8PLyQnx8PKysrBAeHg4AsLW1RUREBCZNmgQHBwfY29tj8uTJaN68Obp06aLX+omIu/qI6MWgdSC6ffs2Zs6ciX379iE7O1vtIokAcOfOHZ0Vl5SUhBkzZmD06NHIzs6Gm5sbRo0ahZkzZ0p9pk6dioKCAowePRo5OTlo27Ytdu3aBRsbG6nPp59+ClNTU4SFhaGgoACdO3fGqlWr1C4bQERERPKldSB65513cPnyZURERMDFxeWpBy8/DxsbGyxcuPCJF3xUKBSIjY1FbGxshX0sLCyQlJSkdkFHIiIiojJaB6JDhw7h0KFDaNGihT7qISIiIjI4rQ+qbtKkCQoKCvRRCxEREZFRaD1DtGTJEkybNg0zZ86Ej48PzMzM1JbXqlVLZ8UREZF2eBA70bPROhDZ2dkhNzcXr732mlp72YUOecNUIiIietFoHYgGDBgAc3NzrFu3Tu8HVRMREREZgtaB6OzZszh58iQaN26sj3qIiIiIDE7rg6oDAgJw/fp1fdRCREREZBRazxCNGzcOEyZMwJQpU9C8eXONg6p9fX11VhwRERGRIWgdiPr16wcA0u0zgH8ujsiDqomIiOhFpXUgysjI0EcdREREREajdSDy8PDQRx1ERERERvNMd7u/fPkyFi5ciPT0dCgUCnh7e2PChAlo2LChrusjIiIi0jutzzLbuXMnmjZtiuPHj8PX1xc+Pj44duwYmjVrhuTkZH3USERERKRXWs8QTZs2DRMnTsTHH3+s0R4dHY2uXbvqrDgiIiIiQ9B6hig9PR0REREa7cOGDcP58+d1UhQRERGRIWkdiJycnJCWlqbRnpaWBmdnZ13URERERGRQWu8yGzFiBEaOHIk//vgD7du3h0KhwKFDhzB37lxMmjRJHzUSERER6ZXWgWjGjBmwsbHB/PnzERMTAwBwc3NDbGwsxo8fr/MCiYiIiPRN60CkUCgwceJETJw4Effu3QMA2NjY6LwwIiIiIkPR+hii1157DXfv3gXwTxAqC0N5eXl47bXXdFocERERkSFoHYj279+PoqIijfaHDx/il19+0UlRRERERIZU6V1mp0+flv59/vx5ZGVlSc9LSkqwY8cO1KlTR7fVERERERlApQNRy5YtoVAooFAoyt01ZmlpiaSkJJ0WR0RERGQIlQ5EGRkZEEKgQYMGOH78OJycnKRl5ubmcHZ2homJiV6KJCIiItKnSgeisrvcl5aW6q0YIiIiImPQ+qDq1atX4+eff5aeT506FXZ2dmjfvj2uXr2q0+KIiIiIDEHrQBQfHw9LS0sAwJEjR7Bo0SIkJibC0dEREydO1HmBRERERPqm9YUZr1+/jkaNGgEAtmzZgjfffBMjR45Ehw4dEBQUpOv6iIiIiPRO6xmimjVr4vbt2wCAXbt2oUuXLgAACwsLFBQU6LY6IiIiIgPQeoaoa9euGD58OPz8/HDx4kX07NkTAHDu3DnUr19f1/URERER6Z3WM0SLFy9Gu3btcOvWLXz//fdwcHAAAKSmpuLtt9/WeYFERERE+qb1DJGdnR0WLVqk0R4XF6eTgoiIiIgMTetAdPDgwScu79ix4zMXQ0RERGQMWgei8s4kUygU0r9LSkqeqyAiIiIiQ9P6GKKcnBy1R3Z2Nnbs2IHWrVtj165d+qiRiIiISK+0niGytbXVaOvatSuUSiUmTpyI1NRUnRRGREREZChazxBVxMnJCRcuXNDVcEREREQGo/UM0enTp9WeCyGQmZmJjz/+GC1atNBZYURERESGonUgatmyJRQKBYQQau0vv/wyvvrqK50VRkRERGQoWgeijIwMtec1atSAk5MTLCwsdFYUERERkSFpHYg8PDz0UQcRERGR0VT6oOq9e/eiadOmyMvL01iWm5uLZs2a4ZdfftFpcURERESGUOlAtHDhQowYMQK1atXSWGZra4tRo0ZhwYIFOi2OiIiIyBAqHYhOnTqFbt26Vbg8ODiY1yAiIiKiF1KlA9Fff/0FMzOzCpebmpri1q1bOimKiIiIyJAqHYjq1KmDM2fOVLj89OnTcHV11UlRRERERIZU6UDUo0cPzJw5Ew8fPtRYVlBQgFmzZiE0NFSnxREREREZQqVPu//ggw+wadMmvPTSSxg7diwaN24MhUKB9PR0LF68GCUlJZg+fbo+ayUiIiLSi0oHIhcXFxw+fBjvvfceYmJipCtVKxQKhISEYMmSJXBxcdFboURERET6otXNXT08PLBt2zb8/fffOHbsGI4ePYq///4b27ZtQ/369fVS4J9//ol33nkHDg4OsLKyQsuWLdXOZhNCIDY2Fm5ubrC0tERQUBDOnTunNkZhYSHGjRsHR0dHWFtbo3fv3rhx44Ze6iUiIqIXzzPd7b527dpo3bo12rRpg9q1a+u6JklOTg46dOgAMzMzbN++HefPn8f8+fNhZ2cn9UlMTMSCBQuwaNEipKSkQKVSoWvXrrh3757UJzIyEps3b8aGDRtw6NAh3L9/H6GhoSgpKdFb7URERPTi0PrWHYY0d+5cuLu7Y+XKlVLbv2eihBBYuHAhpk+fjr59+wIAVq9eDRcXF6xbtw6jRo1Cbm4uvvzyS6xZswZdunQBAKxduxbu7u7YvXs3QkJCDLpNREREVPU80wyRofz4448ICAjAW2+9BWdnZ/j5+WH58uXS8oyMDGRlZSE4OFhqUyqVCAwMxOHDhwEAqampKC4uVuvj5uYGHx8fqQ8RERHJW5UORH/88QeWLl0KLy8v7Ny5E++++y7Gjx+Pr7/+GgCQlZUFABoHc7u4uEjLsrKyYG5urrFr7999ylNYWIi8vDy1BxEREVVPlQpErVq1Qk5ODgBg9uzZePDggV6LKlNaWopWrVohPj4efn5+GDVqFEaMGIGlS5eq9VMoFGrPhRAabY97Wp+EhATY2tpKD3d392ffECIiIqrSKhWI0tPTkZ+fDwCIi4vD/fv39VpUGVdXVzRt2lStzdvbG9euXQMAqFQqANCY6cnOzpZmjVQqFYqKiqRAV16f8sTExCA3N1d6XL9+/bm3h4iIiKqmSh1U3bJlSwwdOhSvvPIKhBD45JNPULNmzXL7zpw5U2fFdejQARcuXFBru3jxIjw8PAAAnp6eUKlUSE5Ohp+fHwCgqKgIBw4cwNy5cwEA/v7+MDMzQ3JyMsLCwgAAmZmZOHv2LBITEytct1KphFKp1Nm2EBERUdVVqUC0atUqzJo1Cz/99BMUCgW2b98OU1PNlyoUCp0GookTJ6J9+/aIj49HWFgYjh8/jmXLlmHZsmXS+iIjIxEfHw8vLy94eXkhPj4eVlZWCA8PBwDY2toiIiICkyZNgoODA+zt7TF58mQ0b95cOuuMiIiI5K1Sgahx48bYsGEDAKBGjRrYs2cPnJ2d9VoYALRu3RqbN29GTEwMZs+eDU9PTyxcuBADBgyQ+kydOhUFBQUYPXo0cnJy0LZtW+zatQs2NjZSn08//RSmpqYICwtDQUEBOnfujFWrVsHExETv20BERERVn9bXISotLdVHHRUKDQ194k1jFQoFYmNjERsbW2EfCwsLJCUlISkpSQ8VEhER0YvumS7MePnyZSxcuBDp6elQKBTw9vbGhAkT0LBhQ13XR0RERKR3Wl+HaOfOnWjatCmOHz8OX19f+Pj44NixY2jWrBmSk5P1USMRERGRXmk9QzRt2jRMnDgRH3/8sUZ7dHQ0unbtqrPiiIiIiAxB6xmi9PR0REREaLQPGzYM58+f10lRRERERIakdSBycnJCWlqaRntaWppBzjwjIiIi0jWtd5mNGDECI0eOxB9//IH27dtDoVDg0KFDmDt3LiZNmqSPGomIiIj0SutANGPGDNjY2GD+/PmIiYkB8M/d42NjYzF+/HidF0hERESkb1oHIoVCgYkTJ2LixIm4d+8eAKhdBJGIiIjoRfNM1yEqwyBERERE1YHWB1UTERERVTcMRERERCR7DEREREQke1oFouLiYnTq1AkXL17UVz1EREREBqdVIDIzM8PZs2ehUCj0VQ8RERGRwWm9y2zQoEH48ssv9VELERERkVFofdp9UVERVqxYgeTkZAQEBMDa2lpt+YIFC3RWHBEREZEhaB2Izp49i1atWgGAxrFE3JVGRERELyKtA9G+ffv0UQcRERGR0TzzafeXLl3Czp07UVBQAAAQQuisKCIiIiJD0joQ3b59G507d8ZLL72EHj16IDMzEwAwfPhw3u2eiIiIXkhaB6KJEyfCzMwM165dg5WVldTer18/7NixQ6fFERERERmC1scQ7dq1Czt37kTdunXV2r28vHD16lWdFUZERERkKFrPEOXn56vNDJX5+++/oVQqdVIUERERkSFpHYg6duyIr7/+WnquUChQWlqKefPmoVOnTjotjoiIiMgQtN5lNm/ePAQFBeHEiRMoKirC1KlTce7cOdy5cwf/93//p48aiYiIiPRK6xmipk2b4vTp02jTpg26du2K/Px89O3bFydPnkTDhg31USMRERGRXmk9QwQAKpUKcXFxuq6FiIiIyCieKRDl5OTgyy+/RHp6OhQKBby9vTF06FDY29vruj4iIiIivdN6l9mBAwfg6emJzz77DDk5Obhz5w4+++wzeHp64sCBA/qokYiIiEivtJ4hGjNmDMLCwrB06VKYmJgAAEpKSjB69GiMGTMGZ8+e1XmRRERERPqk9QzR5cuXMWnSJCkMAYCJiQmioqJw+fJlnRZHREREZAhaB6JWrVohPT1doz09PR0tW7bURU1EREREBlWpXWanT5+W/j1+/HhMmDABly5dwssvvwwAOHr0KBYvXoyPP/5YP1USERER6VGlAlHLli2hUCgghJDapk6dqtEvPDwc/fr10111RERERAZQqUCUkZGh7zqIiIiIjKZSgcjDw0PfdRAREREZzTNdmPHPP//E//3f/yE7OxulpaVqy8aPH6+TwoiIiIgMRetAtHLlSrz77rswNzeHg4MDFAqFtEyhUDAQERER0QtH60A0c+ZMzJw5EzExMahRQ+uz9omIiIiqHK0TzYMHD9C/f3+GISIiIqo2tE41ERER+N///qePWoiIiIiMQutdZgkJCQgNDcWOHTvQvHlzmJmZqS1fsGCBzoojIiIiMgStA1F8fDx27tyJxo0bA4DGQdVERERELxqtA9GCBQvw1VdfYciQIXooh4iIiMjwtD6GSKlUokOHDvqohYiIiMgotA5EEyZMQFJSkj5qISIiIjIKrXeZHT9+HHv37sVPP/2EZs2aaRxUvWnTJp0VR0RERGQIWgciOzs79O3bVx+1EBERERnFM926g4iIiKg64eWmiYiISPa0DkSenp5o0KBBhQ99SkhIgEKhQGRkpNQmhEBsbCzc3NxgaWmJoKAgnDt3Tu11hYWFGDduHBwdHWFtbY3evXvjxo0beq2ViIiIXhxa7zL7dxgBgOLiYpw8eRI7duzAlClTdFWXhpSUFCxbtgy+vr5q7YmJiViwYAFWrVqFl156CR999BG6du2KCxcuwMbGRqp569at2LBhAxwcHDBp0iSEhoYiNTUVJiYmequZiIiIXgxaB6IJEyaU27548WKcOHHiuQsqz/379zFgwAAsX74cH330kdQuhMDChQsxffp06UDv1atXw8XFBevWrcOoUaOQm5uLL7/8EmvWrEGXLl0AAGvXroW7uzt2796NkJAQvdRMRERELw6dHUPUvXt3fP/997oaTs2YMWPQs2dPKdCUycjIQFZWFoKDg6U2pVKJwMBAHD58GACQmpqK4uJitT5ubm7w8fGR+pSnsLAQeXl5ag8iIiKqnrSeIarId999B3t7e10NJ9mwYQN+/fVXpKSkaCzLysoCALi4uKi1u7i44OrVq1Ifc3Nz1K5dW6NP2evLk5CQgLi4uOctn4iIiF4AWgciPz8/tZu4CiGQlZWFW7duYcmSJTot7vr165gwYQJ27doFCwuLCvs9flNZIcRTbzT7tD4xMTGIioqSnufl5cHd3b2SlRMREdGLROtA1KdPH7XnNWrUgJOTE4KCgtCkSRNd1QXgn91d2dnZ8Pf3l9pKSkpw8OBBLFq0CBcuXADwzyyQq6ur1Cc7O1uaNVKpVCgqKkJOTo7aLFF2djbat29f4bqVSiWUSqVOt4eIiIiqJq0D0axZs/RRR7k6d+6MM2fOqLUNHToUTZo0QXR0NBo0aACVSoXk5GT4+fkBAIqKinDgwAHMnTsXAODv7w8zMzMkJycjLCwMAJCZmYmzZ88iMTHRYNtCREREVZfOjiHSBxsbG/j4+Ki1WVtbw8HBQWqPjIxEfHw8vLy84OXlhfj4eFhZWSE8PBwAYGtri4iICEyaNAkODg6wt7fH5MmT0bx5c42DtImIiEieKh2IatSo8dTjchQKBR49evTcRWlj6tSpKCgowOjRo5GTk4O2bdti165d0jWIAODTTz+FqakpwsLCUFBQgM6dO2PVqlW8BhEREREB0CIQbd68ucJlhw8fRlJSEoQQOinqSfbv36/2XKFQIDY2FrGxsRW+xsLCAklJSUhKStJvcURERPRCqnQgev311zXafvvtN8TExGDr1q0YMGAAPvzwQ50WR0RERGQIz3Rhxps3b2LEiBHw9fXFo0ePkJaWhtWrV6NevXq6ro+IiIhI77QKRLm5uYiOjkajRo1w7tw57NmzB1u3btU48JmIiIjoRVLpXWaJiYmYO3cuVCoV1q9fX+4uNCIiIqIXUaUD0bRp02BpaYlGjRph9erVWL16dbn9Nm3apLPiiIiIiAyh0oFo0KBBTz3tnoiIiOhFVOlAtGrVKj2WQURERGQ8z3SWGREREVF1wkBEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREslfpe5mR/ijidHfTXDFL6GwsIiIiuWAgIiIiomen0NEf9cK4f9BzlxkRERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREcmeqbELIAIAKBS6GUcI3YxDRESywhkiIiIikj0GIiIiIpI9BiIiIiKSPQYiIiIikj0GIiIiIpK9Kh2IEhIS0Lp1a9jY2MDZ2Rl9+vTBhQsX1PoIIRAbGws3NzdYWloiKCgI586dU+tTWFiIcePGwdHREdbW1ujduzdu3LhhyE0hqloUCt08iIiqiSodiA4cOIAxY8bg6NGjSE5OxqNHjxAcHIz8/HypT2JiIhYsWIBFixYhJSUFKpUKXbt2xb1796Q+kZGR2Lx5MzZs2IBDhw7h/v37CA0NRUlJiTE2i4jkhgGUqMqr0tch2rFjh9rzlStXwtnZGampqejYsSOEEFi4cCGmT5+Ovn37AgBWr14NFxcXrFu3DqNGjUJubi6+/PJLrFmzBl26dAEArF27Fu7u7ti9ezdCQkIMvl1ERERUtVTpGaLH5ebmAgDs7e0BABkZGcjKykJwcLDUR6lUIjAwEIcPHwYApKamori4WK2Pm5sbfHx8pD7lKSwsRF5entqDiIyMMy1EpCcvTCASQiAqKgqvvPIKfHx8AABZWVkAABcXF7W+Li4u0rKsrCyYm5ujdu3aFfYpT0JCAmxtbaWHu7u7LjeHqgt+QRMRVQsvTCAaO3YsTp8+jfXr12ssUzz2hSKE0Gh73NP6xMTEIDc3V3pcv3792QonInpRMfAbFt9vo3ohAtG4cePw448/Yt++fahbt67UrlKpAEBjpic7O1uaNVKpVCgqKkJOTk6FfcqjVCpRq1YttQcRERFVT1U6EAkhMHbsWGzatAl79+6Fp6en2nJPT0+oVCokJydLbUVFRThw4ADat28PAPD394eZmZlan8zMTJw9e1bqQ0RERPJWpc8yGzNmDNatW4cffvgBNjY20kyQra0tLC0toVAoEBkZifj4eHh5ecHLywvx8fGwsrJCeHi41DciIgKTJk2Cg4MD7O3tMXnyZDRv3lw664yIiIjkrUoHoqVLlwIAgoKC1NpXrlyJIUOGAACmTp2KgoICjB49Gjk5OWjbti127doFGxsbqf+nn34KU1NThIWFoaCgAJ07d8aqVatgYmJiqE0hIiKiKqxKByIhxFP7KBQKxMbGIjY2tsI+FhYWSEpKQlJSkg6rIyIiouqiSgciIiIirenqTKtK/FFO1UeVPqiaiIiIyBAYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9kyNXQDpmEKhm3GE0M04RERELwDOEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7MkqEC1ZsgSenp6wsLCAv78/fvnlF2OXRERERFWAbALRxo0bERkZienTp+PkyZN49dVX0b17d1y7ds3YpREREZGRySYQLViwABERERg+fDi8vb2xcOFCuLu7Y+nSpcYujYiIiIxMFoGoqKgIqampCA4OVmsPDg7G4cOHjVQVERERVRWmxi7AEP7++2+UlJTAxcVFrd3FxQVZWVnlvqawsBCFhYXS89zcXABAXl6e7gt8qLuhdFZdZbaTdbNu1l251elsINZdqdXpbCDWXanV6WwgPXy/4v9/bwshnthPFoGojEKhUHsuhNBoK5OQkIC4uDiNdnd3d73Upiu2OhtIZyNVbnU6G4h1V2p1OhuIdVdqdTobiHVXanU6G4h1V2p1OhtIv3Xfu3cPtk9YhywCkaOjI0xMTDRmg7KzszVmjcrExMQgKipKel5aWoo7d+7AwcGhwhBVGXl5eXB3d8f169dRq1atZx6HKofvt2Hx/TYsvt+GxffbsHT1fgshcO/ePbi5uT2xnywCkbm5Ofz9/ZGcnIw33nhDak9OTsbrr79e7muUSiWUSqVam52dnc5qqlWrFn+hDIjvt2Hx/TYsvt+GxffbsHTxfj9pZqiMLAIRAERFRWHgwIEICAhAu3btsGzZMly7dg3vvvuusUsjIiIiI5NNIOrXrx9u376N2bNnIzMzEz4+Pti2bRs8PDyMXRoREREZmWwCEQCMHj0ao0ePNmoNSqUSs2bN0tgdR/rB99uw+H4bFt9vw+L7bViGfr8V4mnnoRERERFVc7K4MCMRERHRkzAQERERkewxEBEREZHsMRARERGR7DEQGdCSJUvg6ekJCwsL+Pv745dffjF2SdVSQkICWrduDRsbGzg7O6NPnz64cOGCscuSjYSEBCgUCkRGRhq7lGrrzz//xDvvvAMHBwdYWVmhZcuWSE1NNXZZ1dKjR4/wwQcfwNPTE5aWlmjQoAFmz56N0tJSY5dWbRw8eBC9evWCm5sbFAoFtmzZorZcCIHY2Fi4ubnB0tISQUFBOHfunM7rYCAykI0bNyIyMhLTp0/HyZMn8eqrr6J79+64du2asUurdg4cOIAxY8bg6NGjSE5OxqNHjxAcHIz8/Hxjl1btpaSkYNmyZfD19TV2KdVWTk4OOnToADMzM2zfvh3nz5/H/PnzdXolffr/5s6di88//xyLFi1Ceno6EhMTMW/ePCQlJRm7tGojPz8fLVq0wKJFi8pdnpiYiAULFmDRokVISUmBSqVC165dce/ePd0WIsgg2rRpI9599121tiZNmohp06YZqSL5yM7OFgDEgQMHjF1KtXbv3j3h5eUlkpOTRWBgoJgwYYKxS6qWoqOjxSuvvGLsMmSjZ8+eYtiwYWptffv2Fe+8846RKqreAIjNmzdLz0tLS4VKpRIff/yx1Pbw4UNha2srPv/8c52umzNEBlBUVITU1FQEBwertQcHB+Pw4cNGqko+cnNzAQD29vZGrqR6GzNmDHr27IkuXboYu5Rq7ccff0RAQADeeustODs7w8/PD8uXLzd2WdXWK6+8gj179uDixYsAgFOnTuHQoUPo0aOHkSuTh4yMDGRlZal9fyqVSgQGBur8+1NWV6o2lr///hslJSVwcXFRa3dxcUFWVpaRqpIHIQSioqLwyiuvwMfHx9jlVFsbNmzAr7/+ipSUFGOXUu398ccfWLp0KaKiovD+++/j+PHjGD9+PJRKJQYNGmTs8qqd6Oho5ObmokmTJjAxMUFJSQnmzJmDt99+29ilyULZd2R5359Xr17V6boYiAxIoVCoPRdCaLSRbo0dOxanT5/GoUOHjF1KtXX9+nVMmDABu3btgoWFhbHLqfZKS0sREBCA+Ph4AICfnx/OnTuHpUuXMhDpwcaNG7F27VqsW7cOzZo1Q1paGiIjI+Hm5obBgwcbuzzZMMT3JwORATg6OsLExERjNig7O1sj9ZLujBs3Dj/++CMOHjyIunXrGrucais1NRXZ2dnw9/eX2kpKSnDw4EEsWrQIhYWFMDExMWKF1YurqyuaNm2q1ubt7Y3vv//eSBVVb1OmTMG0adPQv39/AEDz5s1x9epVJCQkMBAZgEqlAvDPTJGrq6vUro/vTx5DZADm5ubw9/dHcnKyWntycjLat29vpKqqLyEExo4di02bNmHv3r3w9PQ0dknVWufOnXHmzBmkpaVJj4CAAAwYMABpaWkMQzrWoUMHjctIXLx4ER4eHkaqqHp78OABatRQ/6o0MTHhafcG4unpCZVKpfb9WVRUhAMHDuj8+5MzRAYSFRWFgQMHIiAgAO3atcOyZctw7do1vPvuu8YurdoZM2YM1q1bhx9++AE2NjbSzJytrS0sLS2NXF31Y2Njo3F8lrW1NRwcHHjclh5MnDgR7du3R3x8PMLCwnD8+HEsW7YMy5YtM3Zp1VKvXr0wZ84c1KtXD82aNcPJkyexYMECDBs2zNilVRv379/HpUuXpOcZGRlIS0uDvb096tWrh8jISMTHx8PLywteXl6Ij4+HlZUVwsPDdVuITs9ZoydavHix8PDwEObm5qJVq1Y8DVxPAJT7WLlypbFLkw2edq9fW7duFT4+PkKpVIomTZqIZcuWGbukaisvL09MmDBB1KtXT1hYWIgGDRqI6dOni8LCQmOXVm3s27ev3P+zBw8eLIT459T7WbNmCZVKJZRKpejYsaM4c+aMzutQCCGEbiMWERER0YuFxxARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBHRC0OhUDzxMWTIEGOXSEQvKN7LjIheGJmZmdK/N27ciJkzZ6rd6NQY96orLi6GmZmZwddLRLrFGSIiemGoVCrpYWtrC4VCodZ28OBB+Pv7w8LCAg0aNEBcXBwePXokvV6hUGDFihV44403YGVlBS8vL/z444/S8lWrVsHOzk5tnVu2bIFCoZCex8bGomXLlvjqq6/QoEEDKJVKCCGQm5uLkSNHwtnZGbVq1cJrr72GU6dO6f09ISLdYCAiomph586deOeddzB+/HicP38eX3zxBVatWoU5c+ao9YuLi0NYWBhOnz6NHj16YMCAAbhz545W67p06RK+/fZbfP/990hLSwMA9OzZE1lZWdi2bRtSU1PRqlUrdO7cWeuxicg4GIiIqFqYM2cOpk2bhsGDB6NBgwbo2rUrPvzwQ3zxxRdq/YYMGYK3334bjRo1Qnx8PPLz83H8+HGt1lVUVIQ1a9bAz88Pvr6+2LdvH86cOYP//e9/CAgIgJeXFz755BPY2dnhu+++0+VmEpGe8BgiIqoWUlNTkZKSojYjVFJSgocPH+LBgwewsrICAPj6+krLra2tYWNjg+zsbK3W5eHhAScnJ7V1379/Hw4ODmr9CgoKcPny5WfZHCIyMAYiIqoWSktLERcXh759+2oss7CwkP79+AHQCoUCpaWlAIAaNWpACKG2vLi4WGM8a2trjXW7urpi//79Gn0fPyaJiKomBiIiqhZatWqFCxcuoFGjRs88hpOTE+7du4f8/Hwp9JQdI/S0dWdlZcHU1BT169d/5vUTkfEwEBFRtTBz5kyEhobC3d0db731FmrUqIHTp0/jzJkz+Oijjyo1Rtu2bWFlZYX3338f48aNw/Hjx7Fq1aqnvq5Lly5o164d+vTpg7lz56Jx48a4efMmtm3bhj59+iAgIOA5t46I9I0HVRNRtRASEoKffvoJycnJaN26NV5++WUsWLAAHh4elR7D3t4ea9euxbZt29C8eXOsX78esbGxT32dQqHAtm3b0LFjRwwbNgwvvfQS+vfvjytXrsDFxeU5toqIDEUhHt9hTkRERCQznCEiIiIi2WMgIiIiItljICIiIiLZYyAiIiIi2WMgIiIiItljICIiIiLZYyAiIiIi2WMgIiIiItljICIiIiLZYyAiIiIi2WMgIiIiItljICIiIiLZ+396gvUaLrY9XwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data Visualization\n",
    "tenure_exited_0 = df[df.Exited == 0].Tenure\n",
    "tenure_exited_1 = df[df.Exited == 1].Tenure\n",
    "\n",
    "plt.xlabel(\"Tenure\")\n",
    "plt.ylabel(\"Number of Customers\")\n",
    "plt.title(\"Customer Churn Prediction Visualization\")\n",
    "\n",
    "plt.hist([tenure_exited_0, tenure_exited_1], color=['green', 'red'], label=['Exited=0', 'Exited=1'])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bbc9c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreditScore\n",
      "Geography\n",
      "Gender\n",
      "Age\n",
      "Tenure\n",
      "Balance\n",
      "NumOfProducts\n",
      "HasCrCard\n",
      "IsActiveMember\n",
      "EstimatedSalary\n",
      "Exited\n"
     ]
    }
   ],
   "source": [
    "for col in df:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5de08be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_unique_col_values(df):\n",
    "    for column in df:\n",
    "        print(f\"{column} --> {df[column].dtypes} : {df[column].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e178cbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreditScore --> int64 : [619 608 502 699 850 645 822 376 501 684 528 497 476 549 635 616 653 587\n",
      " 726 732 636 510 669 846 577 756 571 574 411 591 533 553 520 722 475 490\n",
      " 804 582 472 465 556 834 660 776 829 637 550 698 585 788 655 601 656 725\n",
      " 511 614 742 687 555 603 751 581 735 661 675 738 813 657 604 519 664 678\n",
      " 757 416 665 777 543 506 493 652 750 729 646 647 808 524 769 730 515 773\n",
      " 814 710 413 623 670 622 785 605 479 685 538 562 721 628 668 828 674 625\n",
      " 432 770 758 795 686 789 589 461 584 579 663 682 793 691 485 650 754 535\n",
      " 716 539 706 586 631 717 800 683 704 615 667 484 480 578 512 606 597 778\n",
      " 514 525 715 580 807 521 759 516 711 618 643 671 689 620 676 572 695 592\n",
      " 567 694 547 594 673 610 767 763 712 703 662 659 523 772 545 634 739 771\n",
      " 681 544 696 766 727 693 557 531 498 651 791 733 811 707 714 782 775 799\n",
      " 602 744 588 747 583 627 731 629 438 642 806 474 559 429 680 749 734 644\n",
      " 626 649 805 718 840 630 654 762 568 613 522 737 648 443 640 540 460 593\n",
      " 801 611 802 745 483 690 492 709 705 560 752 701 537 487 596 702 486 724\n",
      " 548 464 790 534 748 494 590 468 509 818 816 536 753 774 621 569 658 798\n",
      " 641 542 692 639 765 570 638 599 632 779 527 564 833 504 842 508 417 598\n",
      " 741 607 761 848 546 439 755 760 526 713 700 666 566 495 688 612 477 427\n",
      " 839 819 720 459 503 624 529 563 482 796 445 746 786 554 672 787 499 844\n",
      " 450 815 838 803 736 633 600 679 517 792 743 488 421 841 708 507 505 456\n",
      " 435 561 518 565 728 784 552 609 764 697 723 551 444 719 496 541 830 812\n",
      " 677 420 595 617 809 500 826 434 513 478 797 363 399 463 780 452 575 837\n",
      " 794 824 428 823 781 849 489 431 457 768 831 359 820 573 576 558 817 449\n",
      " 440 415 821 530 350 446 425 740 481 783 358 845 451 458 469 423 404 836\n",
      " 473 835 466 491 351 827 843 365 532 414 453 471 401 810 832 470 447 422\n",
      " 825 430 436 426 408 847 418 437 410 454 407 455 462 386 405 383 395 467\n",
      " 433 442 424 448 441 367 412 382 373 419]\n",
      "Geography --> object : ['France' 'Spain' 'Germany']\n",
      "Gender --> object : ['Female' 'Male']\n",
      "Age --> int64 : [42 41 39 43 44 50 29 27 31 24 34 25 35 45 58 32 38 46 36 33 40 51 61 49\n",
      " 37 19 66 56 26 21 55 75 22 30 28 65 48 52 57 73 47 54 72 20 67 79 62 53\n",
      " 80 59 68 23 60 70 63 64 18 82 69 74 71 76 77 88 85 84 78 81 92 83]\n",
      "Tenure --> int64 : [ 2  1  8  7  4  6  3 10  5  9  0]\n",
      "Balance --> float64 : [     0.    83807.86 159660.8  ...  57369.61  75075.31 130142.79]\n",
      "NumOfProducts --> int64 : [1 3 2 4]\n",
      "HasCrCard --> int64 : [1 0]\n",
      "IsActiveMember --> int64 : [1 0]\n",
      "EstimatedSalary --> float64 : [101348.88 112542.58 113931.57 ...  42085.58  92888.52  38190.78]\n",
      "Exited --> int64 : [1 0]\n"
     ]
    }
   ],
   "source": [
    "print_unique_col_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79d63db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suman\\AppData\\Local\\Temp\\ipykernel_16964\\3407678644.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Gender'].replace({'Female':1, 'Male':0}, inplace=True)\n",
      "C:\\Users\\suman\\AppData\\Local\\Temp\\ipykernel_16964\\3407678644.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['Gender'].replace({'Female':1, 'Male':0}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df['Gender'].replace({'Female':1, 'Male':0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41ef2a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   CreditScore      10000 non-null  int64  \n",
      " 1   Geography        10000 non-null  object \n",
      " 2   Gender           10000 non-null  int64  \n",
      " 3   Age              10000 non-null  int64  \n",
      " 4   Tenure           10000 non-null  int64  \n",
      " 5   Balance          10000 non-null  float64\n",
      " 6   NumOfProducts    10000 non-null  int64  \n",
      " 7   HasCrCard        10000 non-null  int64  \n",
      " 8   IsActiveMember   10000 non-null  int64  \n",
      " 9   EstimatedSalary  10000 non-null  float64\n",
      " 10  Exited           10000 non-null  int64  \n",
      "dtypes: float64(2), int64(8), object(1)\n",
      "memory usage: 859.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328b5384",
   "metadata": {},
   "source": [
    "#### Using One hot encoding for column \"Geography\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a8cbe12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CreditScore', 'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts',\n",
       "       'HasCrCard', 'IsActiveMember', 'EstimatedSalary', 'Exited',\n",
       "       'Geography_France', 'Geography_Germany', 'Geography_Spain'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.get_dummies(data=df, columns=['Geography'])\n",
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "508af768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>563</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>6</td>\n",
       "      <td>139810.34</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>152417.79</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>741</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>7</td>\n",
       "      <td>143637.58</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>174227.66</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>650</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>106967.18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24495.03</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     CreditScore  Gender  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "966          563       1   34       6  139810.34              1          1   \n",
       "857          741       0   39       7  143637.58              2          0   \n",
       "147          650       0   37       5  106967.18              1          0   \n",
       "\n",
       "     IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
       "966               1        152417.79       0              True   \n",
       "857               1        174227.66       0             False   \n",
       "147               0         24495.03       0              True   \n",
       "\n",
       "     Geography_Germany  Geography_Spain  \n",
       "966              False            False  \n",
       "857              False             True  \n",
       "147              False            False  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76204568",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suman\\AppData\\Local\\Temp\\ipykernel_16964\\756362938.py:2: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df1 = df1.applymap(lambda x: int(x) if isinstance(x, bool) else x)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CreditScore            int64\n",
       "Gender                 int64\n",
       "Age                    int64\n",
       "Tenure                 int64\n",
       "Balance              float64\n",
       "NumOfProducts          int64\n",
       "HasCrCard              int64\n",
       "IsActiveMember         int64\n",
       "EstimatedSalary      float64\n",
       "Exited                 int64\n",
       "Geography_France       int64\n",
       "Geography_Germany      int64\n",
       "Geography_Spain        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert all boolean columns to integers\n",
    "df1 = df1.applymap(lambda x: int(x) if isinstance(x, bool) else x)\n",
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6d0fd5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Gender  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619       1   42       2       0.00              1          1   \n",
       "1          608       1   41       1   83807.86              1          0   \n",
       "2          502       1   42       8  159660.80              3          1   \n",
       "3          699       1   39       1       0.00              2          0   \n",
       "4          850       1   43       2  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
       "0               1        101348.88       1                 1   \n",
       "1               1        112542.58       0                 0   \n",
       "2               0        113931.57       1                 1   \n",
       "3               0         93826.63       0                 1   \n",
       "4               1         79084.10       0                 0   \n",
       "\n",
       "   Geography_Germany  Geography_Spain  \n",
       "0                  0                0  \n",
       "1                  0                1  \n",
       "2                  0                0  \n",
       "3                  0                0  \n",
       "4                  0                1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9171b93",
   "metadata": {},
   "source": [
    "### Preprocessing/Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ef15ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_scale = ['CreditScore', 'Tenure', 'Balance', 'EstimatedSalary']\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df1[cols_to_scale] = scaler.fit_transform(df1[cols_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d760ed48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>0.812</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.055943</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2185</th>\n",
       "      <td>0.778</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.437156</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.966641</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4967</th>\n",
       "      <td>0.542</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.694014</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.862478</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3660</th>\n",
       "      <td>0.288</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5556</th>\n",
       "      <td>0.512</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.476296</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.233839</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender  Age  Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
       "276         0.812       0   62     0.3  0.000000              1          1   \n",
       "2185        0.778       0   40     0.1  0.437156              1          1   \n",
       "4967        0.542       0   40     0.8  0.694014              3          1   \n",
       "3660        0.288       0   27     0.2  0.000000              2          1   \n",
       "5556        0.512       0   40     0.6  0.476296              2          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
       "276                1         0.055943       1                 1   \n",
       "2185               1         0.966641       0                 0   \n",
       "4967               0         0.862478       1                 0   \n",
       "3660               0         0.111976       0                 0   \n",
       "5556               0         0.233839       0                 1   \n",
       "\n",
       "      Geography_Germany  Geography_Spain  \n",
       "276                   0                0  \n",
       "2185                  0                1  \n",
       "4967                  1                0  \n",
       "3660                  0                1  \n",
       "5556                  0                0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15d80d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CreditScore', 'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts',\n",
       "       'HasCrCard', 'IsActiveMember', 'EstimatedSalary', 'Exited',\n",
       "       'Geography_France', 'Geography_Germany', 'Geography_Spain'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a040601",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1.drop('Exited', axis='columns')\n",
    "y = df1['Exited']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2717153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 12), (8000,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab8b69d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000, 12), (2000,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "505a15c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60757f0",
   "metadata": {},
   "source": [
    "### Building an ANN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24d0a1cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suman\\anaconda3\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from tensorflow_addons import losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f8a2743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8580493",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN(X_train, y_train, X_test, y_test, loss, weights):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(12, input_dim=12, activation='relu'),\n",
    "        keras.layers.Dense(6, activation='relu'),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
    "    \n",
    "    if weights == -1:\n",
    "        model.fit(X_train, y_train, epochs=100)\n",
    "    else:\n",
    "        model.fit(X_train, y_train, epochs=100, class_weight=weights)\n",
    "        \n",
    "    print(model.evaluate(X_test, y_test))\n",
    "    \n",
    "    y_preds = model.predict(X_test)\n",
    "    y_preds = np.round(y_preds)\n",
    "    \n",
    "    print(\"Classification Report: \\n\", classification_report(y_test, y_preds))\n",
    "    \n",
    "    return y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0234a558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 1ms/step - loss: 0.5575 - accuracy: 0.7951\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4761 - accuracy: 0.7980\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4578 - accuracy: 0.8040\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4488 - accuracy: 0.8116\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4436 - accuracy: 0.8133\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4392 - accuracy: 0.8138\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4370 - accuracy: 0.8169\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4353 - accuracy: 0.8145\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4346 - accuracy: 0.8188\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4317 - accuracy: 0.8185\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4329 - accuracy: 0.8190\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 0s 997us/step - loss: 0.4277 - accuracy: 0.8198\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 0s 945us/step - loss: 0.4254 - accuracy: 0.8238\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4258 - accuracy: 0.8244\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4243 - accuracy: 0.8216\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 0s 992us/step - loss: 0.4252 - accuracy: 0.8215\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4221 - accuracy: 0.8231\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4215 - accuracy: 0.8234\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4205 - accuracy: 0.8240\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4210 - accuracy: 0.8242\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 0s 940us/step - loss: 0.4160 - accuracy: 0.8285\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4193 - accuracy: 0.8265\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4177 - accuracy: 0.8251\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4152 - accuracy: 0.8270\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4147 - accuracy: 0.8295\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 0s 910us/step - loss: 0.4147 - accuracy: 0.8257\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 0s 916us/step - loss: 0.4119 - accuracy: 0.8298\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 0s 911us/step - loss: 0.4139 - accuracy: 0.8288\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 0s 931us/step - loss: 0.4128 - accuracy: 0.8298\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4112 - accuracy: 0.8309\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4130 - accuracy: 0.8282\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4094 - accuracy: 0.8339\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4120 - accuracy: 0.8309\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 0s 978us/step - loss: 0.4118 - accuracy: 0.8298\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 0s 975us/step - loss: 0.4091 - accuracy: 0.8319\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4098 - accuracy: 0.8311\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4081 - accuracy: 0.8332\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4064 - accuracy: 0.8350\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4078 - accuracy: 0.8332\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4078 - accuracy: 0.8341\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4081 - accuracy: 0.8326\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 0s 991us/step - loss: 0.4080 - accuracy: 0.8314\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 0s 970us/step - loss: 0.4071 - accuracy: 0.8288\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 0s 994us/step - loss: 0.4050 - accuracy: 0.8313\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 0s 985us/step - loss: 0.4080 - accuracy: 0.8329\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 0s 982us/step - loss: 0.4060 - accuracy: 0.8355\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.4053 - accuracy: 0.8345\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 0s 991us/step - loss: 0.4066 - accuracy: 0.8328\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.4040 - accuracy: 0.8353\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4037 - accuracy: 0.8344\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 0s 980us/step - loss: 0.4054 - accuracy: 0.8334\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4044 - accuracy: 0.8325\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 0s 977us/step - loss: 0.4047 - accuracy: 0.8345\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 0s 991us/step - loss: 0.4029 - accuracy: 0.8359\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4030 - accuracy: 0.8342\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 0s 995us/step - loss: 0.4060 - accuracy: 0.8304\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 0s 975us/step - loss: 0.4053 - accuracy: 0.8328\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 0s 986us/step - loss: 0.4022 - accuracy: 0.8351\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 0s 985us/step - loss: 0.4012 - accuracy: 0.8354\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 0s 946us/step - loss: 0.4028 - accuracy: 0.8331\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 0s 973us/step - loss: 0.4019 - accuracy: 0.8355\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 0s 1000us/step - loss: 0.4021 - accuracy: 0.8340\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 0s 975us/step - loss: 0.4024 - accuracy: 0.8331\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 0s 986us/step - loss: 0.4015 - accuracy: 0.8359\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4016 - accuracy: 0.8342\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4013 - accuracy: 0.8351\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4024 - accuracy: 0.8360\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 0s 980us/step - loss: 0.3994 - accuracy: 0.8357\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 0s 954us/step - loss: 0.3998 - accuracy: 0.8353\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4016 - accuracy: 0.8338\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 0s 953us/step - loss: 0.4007 - accuracy: 0.8350\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 0s 982us/step - loss: 0.3994 - accuracy: 0.8361\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3989 - accuracy: 0.8351\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3997 - accuracy: 0.8378\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4010 - accuracy: 0.8328\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4002 - accuracy: 0.8338\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 0s 976us/step - loss: 0.4017 - accuracy: 0.8332\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 0s 972us/step - loss: 0.4011 - accuracy: 0.8354\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3992 - accuracy: 0.8359\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 988us/step - loss: 0.3987 - accuracy: 0.8363\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 0s 956us/step - loss: 0.3997 - accuracy: 0.8335\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 0s 980us/step - loss: 0.4008 - accuracy: 0.8356\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 0s 966us/step - loss: 0.3978 - accuracy: 0.8375\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 0s 944us/step - loss: 0.4012 - accuracy: 0.8359\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 0s 946us/step - loss: 0.3989 - accuracy: 0.8339\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4007 - accuracy: 0.8353\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4019 - accuracy: 0.8307\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3969 - accuracy: 0.8388\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3996 - accuracy: 0.8364\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3991 - accuracy: 0.8359\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3982 - accuracy: 0.8366\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3994 - accuracy: 0.8361\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3984 - accuracy: 0.8356\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3991 - accuracy: 0.8342\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3982 - accuracy: 0.8395\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3996 - accuracy: 0.8366\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3984 - accuracy: 0.8347\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4015 - accuracy: 0.8367\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3984 - accuracy: 0.8360\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3985 - accuracy: 0.8361\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4045 - accuracy: 0.8280\n",
      "[0.40446737408638, 0.828000009059906]\n",
      "63/63 [==============================] - 0s 887us/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.90      1595\n",
      "           1       0.68      0.29      0.40       405\n",
      "\n",
      "    accuracy                           0.83      2000\n",
      "   macro avg       0.76      0.63      0.65      2000\n",
      "weighted avg       0.81      0.83      0.80      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628dbe96",
   "metadata": {},
   "source": [
    "## Mitigating Skewness of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d89037",
   "metadata": {},
   "source": [
    "### Method 1: Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ef922c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class count\n",
    "count_class_0, count_class_1 = df1.Exited.value_counts()\n",
    "# Divide by class\n",
    "df_class_0 = df1[df1['Exited'] == 0]\n",
    "df_class_1 = df1[df1['Exited'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e3d6620d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7963, 13)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "375cd35e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2037, 13)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bd8aed60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random under-sampling:\n",
      "Exited\n",
      "0    2037\n",
      "1    2037\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Undersample 0-class and concat the DataFrames of both class\n",
    "df_class_0_under = df_class_0.sample(count_class_1)\n",
    "df_test_under = pd.concat([df_class_0_under, df_class_1], axis=0)\n",
    "\n",
    "print(\"Random under-sampling:\")\n",
    "print(df_test_under.Exited.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "47bd8e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_test_under.drop('Exited', axis='columns')\n",
    "y = df_test_under['Exited']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c29c7d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exited\n",
       "1    1630\n",
       "0    1629\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ec28d054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "102/102 [==============================] - 2s 3ms/step - loss: 1.2690 - accuracy: 0.4544\n",
      "Epoch 2/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6997 - accuracy: 0.4916\n",
      "Epoch 3/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6734 - accuracy: 0.5750\n",
      "Epoch 4/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6565 - accuracy: 0.6352\n",
      "Epoch 5/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6422 - accuracy: 0.6382\n",
      "Epoch 6/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6266 - accuracy: 0.6640\n",
      "Epoch 7/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6179 - accuracy: 0.6769\n",
      "Epoch 8/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6101 - accuracy: 0.6784\n",
      "Epoch 9/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6018 - accuracy: 0.6852\n",
      "Epoch 10/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5993 - accuracy: 0.6840\n",
      "Epoch 11/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5972 - accuracy: 0.6830\n",
      "Epoch 12/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5958 - accuracy: 0.6855\n",
      "Epoch 13/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5923 - accuracy: 0.6864\n",
      "Epoch 14/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5903 - accuracy: 0.6886\n",
      "Epoch 15/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5893 - accuracy: 0.6907\n",
      "Epoch 16/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5890 - accuracy: 0.6910\n",
      "Epoch 17/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5908 - accuracy: 0.6904\n",
      "Epoch 18/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5898 - accuracy: 0.6870\n",
      "Epoch 19/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5909 - accuracy: 0.6836\n",
      "Epoch 20/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5847 - accuracy: 0.6968\n",
      "Epoch 21/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5865 - accuracy: 0.6910\n",
      "Epoch 22/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5848 - accuracy: 0.6968\n",
      "Epoch 23/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5831 - accuracy: 0.6938\n",
      "Epoch 24/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5858 - accuracy: 0.6907\n",
      "Epoch 25/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5825 - accuracy: 0.6935\n",
      "Epoch 26/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5834 - accuracy: 0.6947\n",
      "Epoch 27/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5844 - accuracy: 0.6941\n",
      "Epoch 28/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5802 - accuracy: 0.7008\n",
      "Epoch 29/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5792 - accuracy: 0.6975\n",
      "Epoch 30/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5858 - accuracy: 0.6929\n",
      "Epoch 31/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5790 - accuracy: 0.6978\n",
      "Epoch 32/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5801 - accuracy: 0.7048\n",
      "Epoch 33/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5783 - accuracy: 0.6999\n",
      "Epoch 34/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5782 - accuracy: 0.6959\n",
      "Epoch 35/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5809 - accuracy: 0.7005\n",
      "Epoch 36/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5750 - accuracy: 0.7008\n",
      "Epoch 37/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5746 - accuracy: 0.7042\n",
      "Epoch 38/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5760 - accuracy: 0.7119\n",
      "Epoch 39/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5713 - accuracy: 0.7070\n",
      "Epoch 40/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5724 - accuracy: 0.7027\n",
      "Epoch 41/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5761 - accuracy: 0.7030\n",
      "Epoch 42/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5694 - accuracy: 0.7060\n",
      "Epoch 43/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5721 - accuracy: 0.7082\n",
      "Epoch 44/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5748 - accuracy: 0.6965\n",
      "Epoch 45/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5709 - accuracy: 0.7100\n",
      "Epoch 46/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5687 - accuracy: 0.7051\n",
      "Epoch 47/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5696 - accuracy: 0.7076\n",
      "Epoch 48/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5663 - accuracy: 0.7094\n",
      "Epoch 49/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5677 - accuracy: 0.7060\n",
      "Epoch 50/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5656 - accuracy: 0.7106\n",
      "Epoch 51/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5679 - accuracy: 0.7079\n",
      "Epoch 52/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5621 - accuracy: 0.7116\n",
      "Epoch 53/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5628 - accuracy: 0.7103\n",
      "Epoch 54/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5624 - accuracy: 0.7159\n",
      "Epoch 55/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5600 - accuracy: 0.7106\n",
      "Epoch 56/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5584 - accuracy: 0.7116\n",
      "Epoch 57/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5596 - accuracy: 0.7183\n",
      "Epoch 58/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5605 - accuracy: 0.7186\n",
      "Epoch 59/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5601 - accuracy: 0.7128\n",
      "Epoch 60/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5598 - accuracy: 0.7165\n",
      "Epoch 61/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5594 - accuracy: 0.7156\n",
      "Epoch 62/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5532 - accuracy: 0.7211\n",
      "Epoch 63/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5549 - accuracy: 0.7208\n",
      "Epoch 64/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5505 - accuracy: 0.7241\n",
      "Epoch 65/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5518 - accuracy: 0.7309\n",
      "Epoch 66/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5509 - accuracy: 0.7217\n",
      "Epoch 67/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5473 - accuracy: 0.7269\n",
      "Epoch 68/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5473 - accuracy: 0.7229\n",
      "Epoch 69/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5488 - accuracy: 0.7275\n",
      "Epoch 70/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5457 - accuracy: 0.7324\n",
      "Epoch 71/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5438 - accuracy: 0.7291\n",
      "Epoch 72/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5456 - accuracy: 0.7318\n",
      "Epoch 73/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5426 - accuracy: 0.7318\n",
      "Epoch 74/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5390 - accuracy: 0.7364\n",
      "Epoch 75/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5416 - accuracy: 0.7315\n",
      "Epoch 76/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5401 - accuracy: 0.7352\n",
      "Epoch 77/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5426 - accuracy: 0.7284\n",
      "Epoch 78/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5355 - accuracy: 0.7370\n",
      "Epoch 79/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5398 - accuracy: 0.7309\n",
      "Epoch 80/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5345 - accuracy: 0.7395\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5358 - accuracy: 0.7432\n",
      "Epoch 82/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5338 - accuracy: 0.7321\n",
      "Epoch 83/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5375 - accuracy: 0.7355\n",
      "Epoch 84/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5279 - accuracy: 0.7475\n",
      "Epoch 85/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5309 - accuracy: 0.7373\n",
      "Epoch 86/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5293 - accuracy: 0.7367\n",
      "Epoch 87/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5325 - accuracy: 0.7407\n",
      "Epoch 88/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5256 - accuracy: 0.7410\n",
      "Epoch 89/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5263 - accuracy: 0.7404\n",
      "Epoch 90/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5257 - accuracy: 0.7432\n",
      "Epoch 91/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5233 - accuracy: 0.7450\n",
      "Epoch 92/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5262 - accuracy: 0.7395\n",
      "Epoch 93/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5285 - accuracy: 0.7407\n",
      "Epoch 94/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5233 - accuracy: 0.7447\n",
      "Epoch 95/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5248 - accuracy: 0.7453\n",
      "Epoch 96/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5245 - accuracy: 0.7423\n",
      "Epoch 97/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5205 - accuracy: 0.7438\n",
      "Epoch 98/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5253 - accuracy: 0.7481\n",
      "Epoch 99/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5203 - accuracy: 0.7508\n",
      "Epoch 100/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5197 - accuracy: 0.7481\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5317 - accuracy: 0.7288\n",
      "[0.5317170023918152, 0.728834331035614]\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.63      0.70       408\n",
      "           1       0.69      0.83      0.75       407\n",
      "\n",
      "    accuracy                           0.73       815\n",
      "   macro avg       0.74      0.73      0.73       815\n",
      "weighted avg       0.74      0.73      0.73       815\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051a6c5d",
   "metadata": {},
   "source": [
    "### Method 2: Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d2432af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random over-sampling:\n",
      "Exited\n",
      "0    7963\n",
      "1    7963\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Oversample 1-class and concat DataFrames of both classes\n",
    "df_class_1_over = df_class_1.sample(count_class_0, replace=True)\n",
    "df_test_over = pd.concat([df_class_0, df_class_1_over], axis=0)\n",
    "\n",
    "print('Random over-sampling:')\n",
    "print(df_test_over.Exited.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7b166c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_test_over.drop('Exited',axis='columns')\n",
    "y = df_test_over['Exited']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5cca4915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exited\n",
       "0    6370\n",
       "1    6370\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "64101b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "399/399 [==============================] - 3s 4ms/step - loss: 0.7045 - accuracy: 0.5533\n",
      "Epoch 2/100\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.6215 - accuracy: 0.6626\n",
      "Epoch 3/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5958 - accuracy: 0.6879\n",
      "Epoch 4/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5883 - accuracy: 0.6947\n",
      "Epoch 5/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5863 - accuracy: 0.6962\n",
      "Epoch 6/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5834 - accuracy: 0.6981\n",
      "Epoch 7/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5816 - accuracy: 0.6989\n",
      "Epoch 8/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5801 - accuracy: 0.7038\n",
      "Epoch 9/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5809 - accuracy: 0.6960\n",
      "Epoch 10/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5805 - accuracy: 0.6980\n",
      "Epoch 11/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5792 - accuracy: 0.7005\n",
      "Epoch 12/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5795 - accuracy: 0.6984\n",
      "Epoch 13/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5794 - accuracy: 0.7018\n",
      "Epoch 14/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5790 - accuracy: 0.7027\n",
      "Epoch 15/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5789 - accuracy: 0.7014\n",
      "Epoch 16/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5787 - accuracy: 0.7007\n",
      "Epoch 17/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5790 - accuracy: 0.7031\n",
      "Epoch 18/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5789 - accuracy: 0.7032\n",
      "Epoch 19/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5801 - accuracy: 0.7005\n",
      "Epoch 20/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5778 - accuracy: 0.7048\n",
      "Epoch 21/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5784 - accuracy: 0.7033\n",
      "Epoch 22/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5781 - accuracy: 0.7047\n",
      "Epoch 23/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5780 - accuracy: 0.7035\n",
      "Epoch 24/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5781 - accuracy: 0.7031\n",
      "Epoch 25/100\n",
      "399/399 [==============================] - 1s 4ms/step - loss: 0.5772 - accuracy: 0.7044\n",
      "Epoch 26/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5775 - accuracy: 0.7046\n",
      "Epoch 27/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5771 - accuracy: 0.7040\n",
      "Epoch 28/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5774 - accuracy: 0.7039\n",
      "Epoch 29/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5780 - accuracy: 0.7037\n",
      "Epoch 30/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5772 - accuracy: 0.7045\n",
      "Epoch 31/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5776 - accuracy: 0.7031\n",
      "Epoch 32/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5783 - accuracy: 0.7045\n",
      "Epoch 33/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5769 - accuracy: 0.7034\n",
      "Epoch 34/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5782 - accuracy: 0.7031\n",
      "Epoch 35/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5792 - accuracy: 0.6995\n",
      "Epoch 36/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5777 - accuracy: 0.7055\n",
      "Epoch 37/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5772 - accuracy: 0.7034\n",
      "Epoch 38/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5762 - accuracy: 0.7058\n",
      "Epoch 39/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5782 - accuracy: 0.7047\n",
      "Epoch 40/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5761 - accuracy: 0.7064\n",
      "Epoch 41/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5750 - accuracy: 0.7059\n",
      "Epoch 42/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5767 - accuracy: 0.7062\n",
      "Epoch 43/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5773 - accuracy: 0.7045\n",
      "Epoch 44/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5767 - accuracy: 0.7051\n",
      "Epoch 45/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5765 - accuracy: 0.7020\n",
      "Epoch 46/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5763 - accuracy: 0.7070\n",
      "Epoch 47/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5776 - accuracy: 0.7028\n",
      "Epoch 48/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5783 - accuracy: 0.7039\n",
      "Epoch 49/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5762 - accuracy: 0.7049\n",
      "Epoch 50/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5773 - accuracy: 0.7051\n",
      "Epoch 51/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5770 - accuracy: 0.7027\n",
      "Epoch 52/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5760 - accuracy: 0.7029\n",
      "Epoch 53/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5782 - accuracy: 0.7032\n",
      "Epoch 54/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5768 - accuracy: 0.7045\n",
      "Epoch 55/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5771 - accuracy: 0.7052\n",
      "Epoch 56/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5756 - accuracy: 0.7064\n",
      "Epoch 57/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5755 - accuracy: 0.7074\n",
      "Epoch 58/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5766 - accuracy: 0.7057\n",
      "Epoch 59/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5764 - accuracy: 0.7051\n",
      "Epoch 60/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5776 - accuracy: 0.7014\n",
      "Epoch 61/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5766 - accuracy: 0.7046\n",
      "Epoch 62/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5774 - accuracy: 0.7055\n",
      "Epoch 63/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5760 - accuracy: 0.7035\n",
      "Epoch 64/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5764 - accuracy: 0.7044\n",
      "Epoch 65/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5751 - accuracy: 0.7046\n",
      "Epoch 66/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5768 - accuracy: 0.7039\n",
      "Epoch 67/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5752 - accuracy: 0.7079\n",
      "Epoch 68/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5758 - accuracy: 0.7057\n",
      "Epoch 69/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5763 - accuracy: 0.7053\n",
      "Epoch 70/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5759 - accuracy: 0.7042\n",
      "Epoch 71/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5753 - accuracy: 0.7045\n",
      "Epoch 72/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5764 - accuracy: 0.7051\n",
      "Epoch 73/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5758 - accuracy: 0.7074\n",
      "Epoch 74/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5752 - accuracy: 0.7057\n",
      "Epoch 75/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5756 - accuracy: 0.7057\n",
      "Epoch 76/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5747 - accuracy: 0.7081\n",
      "Epoch 77/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5755 - accuracy: 0.7035\n",
      "Epoch 78/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5754 - accuracy: 0.7041\n",
      "Epoch 79/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5755 - accuracy: 0.7051\n",
      "Epoch 80/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5757 - accuracy: 0.7041\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5758 - accuracy: 0.7044\n",
      "Epoch 82/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5753 - accuracy: 0.7049\n",
      "Epoch 83/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5762 - accuracy: 0.7016\n",
      "Epoch 84/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5749 - accuracy: 0.7063\n",
      "Epoch 85/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5740 - accuracy: 0.7062\n",
      "Epoch 86/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5740 - accuracy: 0.7061\n",
      "Epoch 87/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5747 - accuracy: 0.7059\n",
      "Epoch 88/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5752 - accuracy: 0.7034\n",
      "Epoch 89/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5718 - accuracy: 0.7073\n",
      "Epoch 90/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5724 - accuracy: 0.7073\n",
      "Epoch 91/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5713 - accuracy: 0.7068\n",
      "Epoch 92/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5712 - accuracy: 0.7067\n",
      "Epoch 93/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5702 - accuracy: 0.7049\n",
      "Epoch 94/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5708 - accuracy: 0.7084\n",
      "Epoch 95/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5705 - accuracy: 0.7050\n",
      "Epoch 96/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5692 - accuracy: 0.7057\n",
      "Epoch 97/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5691 - accuracy: 0.7056\n",
      "Epoch 98/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5691 - accuracy: 0.7063\n",
      "Epoch 99/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5685 - accuracy: 0.7057\n",
      "Epoch 100/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5678 - accuracy: 0.7056\n",
      "100/100 [==============================] - 1s 2ms/step - loss: 0.5600 - accuracy: 0.7050\n",
      "[0.5600447058677673, 0.7049592137336731]\n",
      "100/100 [==============================] - 0s 2ms/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.72      0.71      1593\n",
      "           1       0.71      0.69      0.70      1593\n",
      "\n",
      "    accuracy                           0.70      3186\n",
      "   macro avg       0.71      0.70      0.70      3186\n",
      "weighted avg       0.71      0.70      0.70      3186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss = keras.losses.BinaryCrossentropy()\n",
    "weights = -1\n",
    "y_preds = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d005eae",
   "metadata": {},
   "source": [
    "### Method 3: SMOTE\n",
    "\n",
    "SMOTE --> Synthetic Minority Over-sampling Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6015fb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1.drop('Exited', axis=1)\n",
    "y = df1['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b6ebdd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(sampling_strategy='minority')\n",
    "X_sm, y_sm = smote.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "89fb73cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exited\n",
       "1    7963\n",
       "0    7963\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sm.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e1feb0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sm, y_sm, test_size=0.2, random_state=15, stratify=y_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d5c1e8fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exited\n",
       "0    6370\n",
       "1    6370\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b61e746f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "399/399 [==============================] - 3s 4ms/step - loss: 0.6403 - accuracy: 0.6258\n",
      "Epoch 2/100\n",
      "399/399 [==============================] - 1s 4ms/step - loss: 0.5793 - accuracy: 0.6976\n",
      "Epoch 3/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5705 - accuracy: 0.7004\n",
      "Epoch 4/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5694 - accuracy: 0.7039\n",
      "Epoch 5/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5672 - accuracy: 0.7074\n",
      "Epoch 6/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5662 - accuracy: 0.7060\n",
      "Epoch 7/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5669 - accuracy: 0.7032\n",
      "Epoch 8/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5665 - accuracy: 0.7082\n",
      "Epoch 9/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5653 - accuracy: 0.7094\n",
      "Epoch 10/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5652 - accuracy: 0.7095\n",
      "Epoch 11/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5657 - accuracy: 0.7097\n",
      "Epoch 12/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5650 - accuracy: 0.7091\n",
      "Epoch 13/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5662 - accuracy: 0.7090\n",
      "Epoch 14/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5645 - accuracy: 0.7083\n",
      "Epoch 15/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5643 - accuracy: 0.7097\n",
      "Epoch 16/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5651 - accuracy: 0.7083\n",
      "Epoch 17/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5637 - accuracy: 0.7133\n",
      "Epoch 18/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5645 - accuracy: 0.7064\n",
      "Epoch 19/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5632 - accuracy: 0.7086\n",
      "Epoch 20/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5647 - accuracy: 0.7094\n",
      "Epoch 21/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5634 - accuracy: 0.7111\n",
      "Epoch 22/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5629 - accuracy: 0.7085\n",
      "Epoch 23/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5642 - accuracy: 0.7108\n",
      "Epoch 24/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5629 - accuracy: 0.7144\n",
      "Epoch 25/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5627 - accuracy: 0.7122\n",
      "Epoch 26/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5639 - accuracy: 0.7071\n",
      "Epoch 27/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5633 - accuracy: 0.7082\n",
      "Epoch 28/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5626 - accuracy: 0.7111\n",
      "Epoch 29/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5617 - accuracy: 0.7085\n",
      "Epoch 30/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5632 - accuracy: 0.7091\n",
      "Epoch 31/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5624 - accuracy: 0.7130\n",
      "Epoch 32/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5632 - accuracy: 0.7083\n",
      "Epoch 33/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5620 - accuracy: 0.7130\n",
      "Epoch 34/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5628 - accuracy: 0.7105\n",
      "Epoch 35/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5628 - accuracy: 0.7115\n",
      "Epoch 36/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5616 - accuracy: 0.7131\n",
      "Epoch 37/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5616 - accuracy: 0.7121\n",
      "Epoch 38/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5621 - accuracy: 0.7133\n",
      "Epoch 39/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5609 - accuracy: 0.7138\n",
      "Epoch 40/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5608 - accuracy: 0.7123\n",
      "Epoch 41/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5607 - accuracy: 0.7133\n",
      "Epoch 42/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5589 - accuracy: 0.7148\n",
      "Epoch 43/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5580 - accuracy: 0.7159\n",
      "Epoch 44/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5561 - accuracy: 0.7187\n",
      "Epoch 45/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5546 - accuracy: 0.7167\n",
      "Epoch 46/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5551 - accuracy: 0.7189\n",
      "Epoch 47/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5517 - accuracy: 0.7189\n",
      "Epoch 48/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5496 - accuracy: 0.7233\n",
      "Epoch 49/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5482 - accuracy: 0.7233\n",
      "Epoch 50/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5463 - accuracy: 0.7244\n",
      "Epoch 51/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5453 - accuracy: 0.7273\n",
      "Epoch 52/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5423 - accuracy: 0.7310\n",
      "Epoch 53/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5415 - accuracy: 0.7305\n",
      "Epoch 54/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5390 - accuracy: 0.7345\n",
      "Epoch 55/100\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.5368 - accuracy: 0.7381\n",
      "Epoch 56/100\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.5342 - accuracy: 0.7393\n",
      "Epoch 57/100\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.5305 - accuracy: 0.7413\n",
      "Epoch 58/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5300 - accuracy: 0.7425\n",
      "Epoch 59/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5272 - accuracy: 0.7474\n",
      "Epoch 60/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5275 - accuracy: 0.7431\n",
      "Epoch 61/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5230 - accuracy: 0.7447\n",
      "Epoch 62/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5210 - accuracy: 0.7485\n",
      "Epoch 63/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5190 - accuracy: 0.7491\n",
      "Epoch 64/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5179 - accuracy: 0.7509\n",
      "Epoch 65/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5165 - accuracy: 0.7506\n",
      "Epoch 66/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5121 - accuracy: 0.7561\n",
      "Epoch 67/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5105 - accuracy: 0.7582\n",
      "Epoch 68/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5089 - accuracy: 0.7581\n",
      "Epoch 69/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5089 - accuracy: 0.7578\n",
      "Epoch 70/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5055 - accuracy: 0.7594\n",
      "Epoch 71/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5043 - accuracy: 0.7589\n",
      "Epoch 72/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.5051 - accuracy: 0.7607\n",
      "Epoch 73/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5015 - accuracy: 0.7626\n",
      "Epoch 74/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5004 - accuracy: 0.7606\n",
      "Epoch 75/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5021 - accuracy: 0.7589\n",
      "Epoch 76/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.4997 - accuracy: 0.7619\n",
      "Epoch 77/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4975 - accuracy: 0.7617\n",
      "Epoch 78/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.4981 - accuracy: 0.7612\n",
      "Epoch 79/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.4955 - accuracy: 0.7630\n",
      "Epoch 80/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.4945 - accuracy: 0.7666\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399/399 [==============================] - 1s 3ms/step - loss: 0.4970 - accuracy: 0.7645\n",
      "Epoch 82/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.4971 - accuracy: 0.7627\n",
      "Epoch 83/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.4977 - accuracy: 0.7578\n",
      "Epoch 84/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.4918 - accuracy: 0.7642\n",
      "Epoch 85/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.4921 - accuracy: 0.7649\n",
      "Epoch 86/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.4932 - accuracy: 0.7614\n",
      "Epoch 87/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.4913 - accuracy: 0.7645\n",
      "Epoch 88/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.4878 - accuracy: 0.7637\n",
      "Epoch 89/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.4907 - accuracy: 0.7635\n",
      "Epoch 90/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.4900 - accuracy: 0.7622\n",
      "Epoch 91/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.4867 - accuracy: 0.7665\n",
      "Epoch 92/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.4874 - accuracy: 0.7644\n",
      "Epoch 93/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.4877 - accuracy: 0.7648\n",
      "Epoch 94/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.4849 - accuracy: 0.7664\n",
      "Epoch 95/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.4839 - accuracy: 0.7659\n",
      "Epoch 96/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.4854 - accuracy: 0.7645\n",
      "Epoch 97/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.4824 - accuracy: 0.7679\n",
      "Epoch 98/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.4814 - accuracy: 0.7673\n",
      "Epoch 99/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.4820 - accuracy: 0.7681\n",
      "Epoch 100/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.4827 - accuracy: 0.7665\n",
      "100/100 [==============================] - 1s 2ms/step - loss: 0.4658 - accuracy: 0.7781\n",
      "[0.4657926857471466, 0.7780916690826416]\n",
      "100/100 [==============================] - 0s 2ms/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77      1593\n",
      "           1       0.76      0.81      0.79      1593\n",
      "\n",
      "    accuracy                           0.78      3186\n",
      "   macro avg       0.78      0.78      0.78      3186\n",
      "weighted avg       0.78      0.78      0.78      3186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ff6366",
   "metadata": {},
   "source": [
    "### Method 4: Use of Ensemble with Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eb9cecc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exited\n",
       "0    7963\n",
       "1    2037\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.Exited.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c3e0ffa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1.drop('Exited', axis='columns')\n",
    "y = df1['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9ae026cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1bdb7fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exited\n",
       "0    6370\n",
       "1    1630\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "09886543",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = X_train.copy()\n",
    "df2['Exited'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "35adabbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5710</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.554265</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.339721</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3745</th>\n",
       "      <td>0.852</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.371163</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980432</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5429</th>\n",
       "      <td>0.664</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.325318</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>0.648</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.426077</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010339</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8967</th>\n",
       "      <td>0.970</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.417230</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender  Age  Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
       "5710        0.856       0   34     0.5  0.554265              2          0   \n",
       "3745        0.852       1   37     0.1  0.371163              2          1   \n",
       "5429        0.664       1   48     0.7  0.000000              2          1   \n",
       "551         0.648       0   47     0.6  0.426077              1          1   \n",
       "8967        0.970       0   25     0.7  0.000000              2          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Geography_France  Geography_Germany  \\\n",
       "5710               0         0.339721                 1                  0   \n",
       "3745               1         0.980432                 0                  1   \n",
       "5429               0         0.325318                 1                  0   \n",
       "551                1         0.010339                 0                  1   \n",
       "8967               1         0.417230                 1                  0   \n",
       "\n",
       "      Geography_Spain  Exited  \n",
       "5710                0       0  \n",
       "3745                0       0  \n",
       "5429                0       0  \n",
       "551                 0       1  \n",
       "8967                0       0  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e38d8f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_class0 = df2[df2.Exited == 0]\n",
    "df2_class1 = df2[df2.Exited == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0053d805",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_batch(df_majority, df_minority, start, end):\n",
    "    df_train = pd.concat([df_majority[start:end], df_minority], axis=0)\n",
    "    \n",
    "    X_train = df_train.drop('Exited', axis='columns')\n",
    "    y_train = df_train.Exited\n",
    "    \n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e1f54903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "102/102 [==============================] - 2s 3ms/step - loss: 1.2233 - accuracy: 0.5239\n",
      "Epoch 2/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6812 - accuracy: 0.5617\n",
      "Epoch 3/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6719 - accuracy: 0.5936\n",
      "Epoch 4/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6611 - accuracy: 0.6273\n",
      "Epoch 5/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6538 - accuracy: 0.6472\n",
      "Epoch 6/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6436 - accuracy: 0.6635\n",
      "Epoch 7/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6352 - accuracy: 0.6758\n",
      "Epoch 8/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6282 - accuracy: 0.6865\n",
      "Epoch 9/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6192 - accuracy: 0.6972\n",
      "Epoch 10/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6130 - accuracy: 0.6954\n",
      "Epoch 11/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6086 - accuracy: 0.7003\n",
      "Epoch 12/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6018 - accuracy: 0.7018\n",
      "Epoch 13/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5961 - accuracy: 0.7098\n",
      "Epoch 14/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5918 - accuracy: 0.7000\n",
      "Epoch 15/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5875 - accuracy: 0.6982\n",
      "Epoch 16/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5853 - accuracy: 0.7061\n",
      "Epoch 17/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5805 - accuracy: 0.7058\n",
      "Epoch 18/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5769 - accuracy: 0.7147\n",
      "Epoch 19/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5732 - accuracy: 0.7141\n",
      "Epoch 20/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5687 - accuracy: 0.7156\n",
      "Epoch 21/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5639 - accuracy: 0.7255\n",
      "Epoch 22/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5619 - accuracy: 0.7227\n",
      "Epoch 23/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5599 - accuracy: 0.7276\n",
      "Epoch 24/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5535 - accuracy: 0.7371\n",
      "Epoch 25/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5460 - accuracy: 0.7350\n",
      "Epoch 26/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5424 - accuracy: 0.7344\n",
      "Epoch 27/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5376 - accuracy: 0.7414\n",
      "Epoch 28/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5348 - accuracy: 0.7463\n",
      "Epoch 29/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5319 - accuracy: 0.7460\n",
      "Epoch 30/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5323 - accuracy: 0.7417\n",
      "Epoch 31/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5287 - accuracy: 0.7414\n",
      "Epoch 32/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5261 - accuracy: 0.7485\n",
      "Epoch 33/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5252 - accuracy: 0.7525\n",
      "Epoch 34/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5216 - accuracy: 0.7503\n",
      "Epoch 35/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5206 - accuracy: 0.7482\n",
      "Epoch 36/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5188 - accuracy: 0.7546\n",
      "Epoch 37/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5179 - accuracy: 0.7509\n",
      "Epoch 38/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5150 - accuracy: 0.7561\n",
      "Epoch 39/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5127 - accuracy: 0.7617\n",
      "Epoch 40/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5165 - accuracy: 0.7531\n",
      "Epoch 41/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5128 - accuracy: 0.7528\n",
      "Epoch 42/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5115 - accuracy: 0.7583\n",
      "Epoch 43/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5107 - accuracy: 0.7595\n",
      "Epoch 44/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.7567\n",
      "Epoch 45/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.7546\n",
      "Epoch 46/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.7558\n",
      "Epoch 47/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5107 - accuracy: 0.7567\n",
      "Epoch 48/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5121 - accuracy: 0.7546\n",
      "Epoch 49/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.7555\n",
      "Epoch 50/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.7537\n",
      "Epoch 51/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5103 - accuracy: 0.7546\n",
      "Epoch 52/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.7540\n",
      "Epoch 53/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.7512\n",
      "Epoch 54/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.7549\n",
      "Epoch 55/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7592\n",
      "Epoch 56/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7549\n",
      "Epoch 57/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7525\n",
      "Epoch 58/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7546\n",
      "Epoch 59/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7574\n",
      "Epoch 60/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7589\n",
      "Epoch 61/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7604\n",
      "Epoch 62/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7540\n",
      "Epoch 63/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7528\n",
      "Epoch 64/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7660\n",
      "Epoch 65/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5019 - accuracy: 0.7574\n",
      "Epoch 66/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5019 - accuracy: 0.7586\n",
      "Epoch 67/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7604\n",
      "Epoch 68/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5025 - accuracy: 0.7564\n",
      "Epoch 69/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5035 - accuracy: 0.7577\n",
      "Epoch 70/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7509\n",
      "Epoch 71/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7552\n",
      "Epoch 72/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5021 - accuracy: 0.7589\n",
      "Epoch 73/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.7595\n",
      "Epoch 74/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5017 - accuracy: 0.7620\n",
      "Epoch 75/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5028 - accuracy: 0.7546\n",
      "Epoch 76/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4996 - accuracy: 0.7598\n",
      "Epoch 77/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5024 - accuracy: 0.7604\n",
      "Epoch 78/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7561\n",
      "Epoch 79/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7534\n",
      "Epoch 80/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5020 - accuracy: 0.7567\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5024 - accuracy: 0.7546\n",
      "Epoch 82/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7571\n",
      "Epoch 83/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4997 - accuracy: 0.7561\n",
      "Epoch 84/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5005 - accuracy: 0.7552\n",
      "Epoch 85/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5011 - accuracy: 0.7546\n",
      "Epoch 86/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5032 - accuracy: 0.7561\n",
      "Epoch 87/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5016 - accuracy: 0.7577\n",
      "Epoch 88/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5016 - accuracy: 0.7583\n",
      "Epoch 89/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5018 - accuracy: 0.7552\n",
      "Epoch 90/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5009 - accuracy: 0.7620\n",
      "Epoch 91/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5025 - accuracy: 0.7598\n",
      "Epoch 92/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7534\n",
      "Epoch 93/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.7571\n",
      "Epoch 94/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5025 - accuracy: 0.7574\n",
      "Epoch 95/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4996 - accuracy: 0.7601\n",
      "Epoch 96/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4987 - accuracy: 0.7571\n",
      "Epoch 97/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5019 - accuracy: 0.7537\n",
      "Epoch 98/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5025 - accuracy: 0.7574\n",
      "Epoch 99/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.7552\n",
      "Epoch 100/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5002 - accuracy: 0.7552\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.4417 - accuracy: 0.7865\n",
      "[0.44167834520339966, 0.7864999771118164]\n",
      "63/63 [==============================] - 0s 2ms/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.81      0.86      1593\n",
      "           1       0.48      0.69      0.57       407\n",
      "\n",
      "    accuracy                           0.79      2000\n",
      "   macro avg       0.70      0.75      0.71      2000\n",
      "weighted avg       0.82      0.79      0.80      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_train_batch(df2_class0, df2_class1, 0, 1630)\n",
    "y_pred1 = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "afbc4777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "102/102 [==============================] - 2s 3ms/step - loss: 1.6699 - accuracy: 0.5244\n",
      "Epoch 2/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6726 - accuracy: 0.5867\n",
      "Epoch 3/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6622 - accuracy: 0.6180\n",
      "Epoch 4/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6514 - accuracy: 0.6376\n",
      "Epoch 5/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6415 - accuracy: 0.6530\n",
      "Epoch 6/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.6686\n",
      "Epoch 7/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6244 - accuracy: 0.6809\n",
      "Epoch 8/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6184 - accuracy: 0.6846\n",
      "Epoch 9/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6121 - accuracy: 0.6840\n",
      "Epoch 10/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6063 - accuracy: 0.6922\n",
      "Epoch 11/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6019 - accuracy: 0.6932\n",
      "Epoch 12/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5993 - accuracy: 0.6882\n",
      "Epoch 13/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5967 - accuracy: 0.6999\n",
      "Epoch 14/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5945 - accuracy: 0.6968\n",
      "Epoch 15/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5922 - accuracy: 0.6959\n",
      "Epoch 16/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5916 - accuracy: 0.6993\n",
      "Epoch 17/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5915 - accuracy: 0.6941\n",
      "Epoch 18/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5879 - accuracy: 0.6981\n",
      "Epoch 19/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5889 - accuracy: 0.6968\n",
      "Epoch 20/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5857 - accuracy: 0.6981\n",
      "Epoch 21/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5882 - accuracy: 0.6993\n",
      "Epoch 22/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5862 - accuracy: 0.6947\n",
      "Epoch 23/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5862 - accuracy: 0.7014\n",
      "Epoch 24/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5849 - accuracy: 0.6996\n",
      "Epoch 25/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5853 - accuracy: 0.6947\n",
      "Epoch 26/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5827 - accuracy: 0.6993\n",
      "Epoch 27/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5849 - accuracy: 0.6922\n",
      "Epoch 28/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5854 - accuracy: 0.6938\n",
      "Epoch 29/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5829 - accuracy: 0.7002\n",
      "Epoch 30/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5833 - accuracy: 0.6938\n",
      "Epoch 31/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5846 - accuracy: 0.6987\n",
      "Epoch 32/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5854 - accuracy: 0.6956\n",
      "Epoch 33/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5825 - accuracy: 0.6987\n",
      "Epoch 34/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5807 - accuracy: 0.7005\n",
      "Epoch 35/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5825 - accuracy: 0.6999\n",
      "Epoch 36/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5852 - accuracy: 0.6935\n",
      "Epoch 37/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5815 - accuracy: 0.7005\n",
      "Epoch 38/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5821 - accuracy: 0.7008\n",
      "Epoch 39/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5806 - accuracy: 0.6993\n",
      "Epoch 40/100\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.5821 - accuracy: 0.7048\n",
      "Epoch 41/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5822 - accuracy: 0.6999\n",
      "Epoch 42/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5806 - accuracy: 0.7017\n",
      "Epoch 43/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5851 - accuracy: 0.6904\n",
      "Epoch 44/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5806 - accuracy: 0.6996\n",
      "Epoch 45/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5838 - accuracy: 0.6953\n",
      "Epoch 46/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5807 - accuracy: 0.6981\n",
      "Epoch 47/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5801 - accuracy: 0.7002\n",
      "Epoch 48/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5805 - accuracy: 0.6987\n",
      "Epoch 49/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5794 - accuracy: 0.7036\n",
      "Epoch 50/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5805 - accuracy: 0.6984\n",
      "Epoch 51/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5798 - accuracy: 0.7002\n",
      "Epoch 52/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5798 - accuracy: 0.6990\n",
      "Epoch 53/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5808 - accuracy: 0.7024\n",
      "Epoch 54/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5803 - accuracy: 0.7008\n",
      "Epoch 55/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5814 - accuracy: 0.7045\n",
      "Epoch 56/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5793 - accuracy: 0.7030\n",
      "Epoch 57/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5833 - accuracy: 0.7021\n",
      "Epoch 58/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5809 - accuracy: 0.7002\n",
      "Epoch 59/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5794 - accuracy: 0.6996\n",
      "Epoch 60/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5809 - accuracy: 0.6971\n",
      "Epoch 61/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5793 - accuracy: 0.7027\n",
      "Epoch 62/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5823 - accuracy: 0.6996\n",
      "Epoch 63/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5838 - accuracy: 0.7021\n",
      "Epoch 64/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5801 - accuracy: 0.6950\n",
      "Epoch 65/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5811 - accuracy: 0.7039\n",
      "Epoch 66/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5808 - accuracy: 0.7002\n",
      "Epoch 67/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5817 - accuracy: 0.6978\n",
      "Epoch 68/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5821 - accuracy: 0.7021\n",
      "Epoch 69/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5786 - accuracy: 0.7027\n",
      "Epoch 70/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5814 - accuracy: 0.6993\n",
      "Epoch 71/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5827 - accuracy: 0.6953\n",
      "Epoch 72/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5796 - accuracy: 0.7011\n",
      "Epoch 73/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5805 - accuracy: 0.7070\n",
      "Epoch 74/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5790 - accuracy: 0.6990\n",
      "Epoch 75/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5817 - accuracy: 0.6978\n",
      "Epoch 76/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5826 - accuracy: 0.6984\n",
      "Epoch 77/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5807 - accuracy: 0.7008\n",
      "Epoch 78/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5808 - accuracy: 0.7085\n",
      "Epoch 79/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5792 - accuracy: 0.7011\n",
      "Epoch 80/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5791 - accuracy: 0.7039\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5813 - accuracy: 0.6999\n",
      "Epoch 82/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5803 - accuracy: 0.7039\n",
      "Epoch 83/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5798 - accuracy: 0.6999\n",
      "Epoch 84/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5813 - accuracy: 0.7008\n",
      "Epoch 85/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5789 - accuracy: 0.7030\n",
      "Epoch 86/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5806 - accuracy: 0.7005\n",
      "Epoch 87/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5801 - accuracy: 0.7051\n",
      "Epoch 88/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5816 - accuracy: 0.7045\n",
      "Epoch 89/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5797 - accuracy: 0.7008\n",
      "Epoch 90/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5785 - accuracy: 0.7033\n",
      "Epoch 91/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5795 - accuracy: 0.7014\n",
      "Epoch 92/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5805 - accuracy: 0.6962\n",
      "Epoch 93/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5781 - accuracy: 0.7073\n",
      "Epoch 94/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5793 - accuracy: 0.7021\n",
      "Epoch 95/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5856 - accuracy: 0.6971\n",
      "Epoch 96/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5845 - accuracy: 0.6993\n",
      "Epoch 97/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5793 - accuracy: 0.7011\n",
      "Epoch 98/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5774 - accuracy: 0.6996\n",
      "Epoch 99/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5811 - accuracy: 0.7011\n",
      "Epoch 100/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5789 - accuracy: 0.7030\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5552 - accuracy: 0.7140\n",
      "[0.5552483201026917, 0.7139999866485596]\n",
      "63/63 [==============================] - 0s 2ms/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.74      0.80      1593\n",
      "           1       0.38      0.62      0.47       407\n",
      "\n",
      "    accuracy                           0.71      2000\n",
      "   macro avg       0.63      0.68      0.64      2000\n",
      "weighted avg       0.78      0.71      0.74      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_train_batch(df2_class0, df2_class1, 1631, 3260)\n",
    "y_pred2 = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "af71f012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "102/102 [==============================] - 2s 3ms/step - loss: 0.6931 - accuracy: 0.5149\n",
      "Epoch 2/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6735 - accuracy: 0.5796\n",
      "Epoch 3/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6589 - accuracy: 0.6407\n",
      "Epoch 4/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6369 - accuracy: 0.6487\n",
      "Epoch 5/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6106 - accuracy: 0.6840\n",
      "Epoch 6/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6016 - accuracy: 0.6827\n",
      "Epoch 7/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5909 - accuracy: 0.6876\n",
      "Epoch 8/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5867 - accuracy: 0.6919\n",
      "Epoch 9/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5833 - accuracy: 0.6965\n",
      "Epoch 10/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5817 - accuracy: 0.6925\n",
      "Epoch 11/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5794 - accuracy: 0.7042\n",
      "Epoch 12/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5782 - accuracy: 0.6947\n",
      "Epoch 13/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5788 - accuracy: 0.7024\n",
      "Epoch 14/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5764 - accuracy: 0.7008\n",
      "Epoch 15/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5767 - accuracy: 0.7027\n",
      "Epoch 16/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5761 - accuracy: 0.7021\n",
      "Epoch 17/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5769 - accuracy: 0.7039\n",
      "Epoch 18/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5752 - accuracy: 0.7060\n",
      "Epoch 19/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5746 - accuracy: 0.7076\n",
      "Epoch 20/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5744 - accuracy: 0.7045\n",
      "Epoch 21/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5742 - accuracy: 0.7116\n",
      "Epoch 22/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5724 - accuracy: 0.7088\n",
      "Epoch 23/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5722 - accuracy: 0.7128\n",
      "Epoch 24/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5735 - accuracy: 0.7085\n",
      "Epoch 25/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5736 - accuracy: 0.7079\n",
      "Epoch 26/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5723 - accuracy: 0.7113\n",
      "Epoch 27/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5754 - accuracy: 0.7045\n",
      "Epoch 28/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5732 - accuracy: 0.7113\n",
      "Epoch 29/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5736 - accuracy: 0.7088\n",
      "Epoch 30/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5716 - accuracy: 0.7119\n",
      "Epoch 31/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5703 - accuracy: 0.7103\n",
      "Epoch 32/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5717 - accuracy: 0.7149\n",
      "Epoch 33/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5697 - accuracy: 0.7165\n",
      "Epoch 34/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5702 - accuracy: 0.7140\n",
      "Epoch 35/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5729 - accuracy: 0.7070\n",
      "Epoch 36/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5717 - accuracy: 0.7153\n",
      "Epoch 37/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5723 - accuracy: 0.7091\n",
      "Epoch 38/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5705 - accuracy: 0.7131\n",
      "Epoch 39/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5698 - accuracy: 0.7128\n",
      "Epoch 40/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5703 - accuracy: 0.7125\n",
      "Epoch 41/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5699 - accuracy: 0.7113\n",
      "Epoch 42/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5703 - accuracy: 0.7091\n",
      "Epoch 43/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5700 - accuracy: 0.7189\n",
      "Epoch 44/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5700 - accuracy: 0.7177\n",
      "Epoch 45/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5746 - accuracy: 0.7079\n",
      "Epoch 46/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5696 - accuracy: 0.7156\n",
      "Epoch 47/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5707 - accuracy: 0.7140\n",
      "Epoch 48/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5691 - accuracy: 0.7134\n",
      "Epoch 49/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5682 - accuracy: 0.7186\n",
      "Epoch 50/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5704 - accuracy: 0.7180\n",
      "Epoch 51/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5699 - accuracy: 0.7180\n",
      "Epoch 52/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5699 - accuracy: 0.7186\n",
      "Epoch 53/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5701 - accuracy: 0.7177\n",
      "Epoch 54/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5706 - accuracy: 0.7143\n",
      "Epoch 55/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5691 - accuracy: 0.7159\n",
      "Epoch 56/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5697 - accuracy: 0.7088\n",
      "Epoch 57/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5690 - accuracy: 0.7153\n",
      "Epoch 58/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5684 - accuracy: 0.7183\n",
      "Epoch 59/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5715 - accuracy: 0.7119\n",
      "Epoch 60/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5706 - accuracy: 0.7241\n",
      "Epoch 61/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5690 - accuracy: 0.7125\n",
      "Epoch 62/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5691 - accuracy: 0.7149\n",
      "Epoch 63/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5692 - accuracy: 0.7165\n",
      "Epoch 64/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5701 - accuracy: 0.7180\n",
      "Epoch 65/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5683 - accuracy: 0.7183\n",
      "Epoch 66/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5708 - accuracy: 0.7070\n",
      "Epoch 67/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5691 - accuracy: 0.7208\n",
      "Epoch 68/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5686 - accuracy: 0.7159\n",
      "Epoch 69/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5674 - accuracy: 0.7171\n",
      "Epoch 70/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5677 - accuracy: 0.7162\n",
      "Epoch 71/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5687 - accuracy: 0.7168\n",
      "Epoch 72/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5704 - accuracy: 0.7143\n",
      "Epoch 73/100\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.5679 - accuracy: 0.7171\n",
      "Epoch 74/100\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.5658 - accuracy: 0.7202\n",
      "Epoch 75/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5641 - accuracy: 0.7238\n",
      "Epoch 76/100\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.5650 - accuracy: 0.7226\n",
      "Epoch 77/100\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.5640 - accuracy: 0.7229\n",
      "Epoch 78/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5614 - accuracy: 0.7229\n",
      "Epoch 79/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5610 - accuracy: 0.7275\n",
      "Epoch 80/100\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.5577 - accuracy: 0.7278\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5564 - accuracy: 0.7288\n",
      "Epoch 82/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5536 - accuracy: 0.7315\n",
      "Epoch 83/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5513 - accuracy: 0.7324\n",
      "Epoch 84/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5498 - accuracy: 0.7352\n",
      "Epoch 85/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5486 - accuracy: 0.7294\n",
      "Epoch 86/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5456 - accuracy: 0.7337\n",
      "Epoch 87/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5411 - accuracy: 0.7456\n",
      "Epoch 88/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5378 - accuracy: 0.7416\n",
      "Epoch 89/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5392 - accuracy: 0.7435\n",
      "Epoch 90/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5339 - accuracy: 0.7472\n",
      "Epoch 91/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5300 - accuracy: 0.7487\n",
      "Epoch 92/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5296 - accuracy: 0.7490\n",
      "Epoch 93/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5267 - accuracy: 0.7515\n",
      "Epoch 94/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5247 - accuracy: 0.7536\n",
      "Epoch 95/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5219 - accuracy: 0.7588\n",
      "Epoch 96/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5197 - accuracy: 0.7515\n",
      "Epoch 97/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5209 - accuracy: 0.7554\n",
      "Epoch 98/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5159 - accuracy: 0.7597\n",
      "Epoch 99/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5188 - accuracy: 0.7536\n",
      "Epoch 100/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5135 - accuracy: 0.7604\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.7545\n",
      "[0.5096918344497681, 0.7544999718666077]\n",
      "63/63 [==============================] - 0s 3ms/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.77      0.83      1593\n",
      "           1       0.44      0.71      0.54       407\n",
      "\n",
      "    accuracy                           0.75      2000\n",
      "   macro avg       0.67      0.74      0.69      2000\n",
      "weighted avg       0.81      0.75      0.77      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_train_batch(df2_class0, df2_class1, 3261, 4890)\n",
    "y_pred3 = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "82056e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "98/98 [==============================] - 2s 3ms/step - loss: 0.8215 - accuracy: 0.4497\n",
      "Epoch 2/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7077 - accuracy: 0.5220\n",
      "Epoch 3/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6590 - accuracy: 0.5889\n",
      "Epoch 4/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6342 - accuracy: 0.6491\n",
      "Epoch 5/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6129 - accuracy: 0.6632\n",
      "Epoch 6/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6067 - accuracy: 0.6690\n",
      "Epoch 7/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5970 - accuracy: 0.6793\n",
      "Epoch 8/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5912 - accuracy: 0.6825\n",
      "Epoch 9/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5947 - accuracy: 0.6864\n",
      "Epoch 10/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5888 - accuracy: 0.6906\n",
      "Epoch 11/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5874 - accuracy: 0.6896\n",
      "Epoch 12/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5871 - accuracy: 0.6919\n",
      "Epoch 13/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5826 - accuracy: 0.6925\n",
      "Epoch 14/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5814 - accuracy: 0.7047\n",
      "Epoch 15/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5825 - accuracy: 0.6941\n",
      "Epoch 16/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5883 - accuracy: 0.6893\n",
      "Epoch 17/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5821 - accuracy: 0.6970\n",
      "Epoch 18/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5843 - accuracy: 0.6931\n",
      "Epoch 19/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5805 - accuracy: 0.6957\n",
      "Epoch 20/100\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5863 - accuracy: 0.6922\n",
      "Epoch 21/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5916 - accuracy: 0.6977\n",
      "Epoch 22/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5810 - accuracy: 0.6957\n",
      "Epoch 23/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5819 - accuracy: 0.7018\n",
      "Epoch 24/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5843 - accuracy: 0.6954\n",
      "Epoch 25/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5826 - accuracy: 0.6951\n",
      "Epoch 26/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5853 - accuracy: 0.6948\n",
      "Epoch 27/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5819 - accuracy: 0.6925\n",
      "Epoch 28/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5825 - accuracy: 0.7044\n",
      "Epoch 29/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5801 - accuracy: 0.7018\n",
      "Epoch 30/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5768 - accuracy: 0.7002\n",
      "Epoch 31/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5878 - accuracy: 0.6829\n",
      "Epoch 32/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5780 - accuracy: 0.7060\n",
      "Epoch 33/100\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5811 - accuracy: 0.6935\n",
      "Epoch 34/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5795 - accuracy: 0.7015\n",
      "Epoch 35/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5783 - accuracy: 0.7050\n",
      "Epoch 36/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5796 - accuracy: 0.7034\n",
      "Epoch 37/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5773 - accuracy: 0.7018\n",
      "Epoch 38/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5793 - accuracy: 0.7034\n",
      "Epoch 39/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5786 - accuracy: 0.6970\n",
      "Epoch 40/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5801 - accuracy: 0.7057\n",
      "Epoch 41/100\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5790 - accuracy: 0.7022\n",
      "Epoch 42/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5774 - accuracy: 0.6989\n",
      "Epoch 43/100\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5796 - accuracy: 0.7015\n",
      "Epoch 44/100\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5777 - accuracy: 0.6973\n",
      "Epoch 45/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5793 - accuracy: 0.6925\n",
      "Epoch 46/100\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5775 - accuracy: 0.6999\n",
      "Epoch 47/100\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5820 - accuracy: 0.7015\n",
      "Epoch 48/100\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5754 - accuracy: 0.7060\n",
      "Epoch 49/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5765 - accuracy: 0.7018\n",
      "Epoch 50/100\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5826 - accuracy: 0.7002\n",
      "Epoch 51/100\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5804 - accuracy: 0.6999\n",
      "Epoch 52/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5856 - accuracy: 0.6993\n",
      "Epoch 53/100\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5822 - accuracy: 0.7031\n",
      "Epoch 54/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5826 - accuracy: 0.7041\n",
      "Epoch 55/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5775 - accuracy: 0.6980\n",
      "Epoch 56/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5771 - accuracy: 0.7028\n",
      "Epoch 57/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5797 - accuracy: 0.7028\n",
      "Epoch 58/100\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5790 - accuracy: 0.6919\n",
      "Epoch 59/100\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5817 - accuracy: 0.7002\n",
      "Epoch 60/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5833 - accuracy: 0.7044\n",
      "Epoch 61/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5773 - accuracy: 0.7086\n",
      "Epoch 62/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5793 - accuracy: 0.7009\n",
      "Epoch 63/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5768 - accuracy: 0.7041\n",
      "Epoch 64/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5768 - accuracy: 0.7076\n",
      "Epoch 65/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5799 - accuracy: 0.7034\n",
      "Epoch 66/100\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5780 - accuracy: 0.7060\n",
      "Epoch 67/100\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5780 - accuracy: 0.7083\n",
      "Epoch 68/100\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5750 - accuracy: 0.7067\n",
      "Epoch 69/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5770 - accuracy: 0.7092\n",
      "Epoch 70/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5797 - accuracy: 0.7012\n",
      "Epoch 71/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5777 - accuracy: 0.7031\n",
      "Epoch 72/100\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5811 - accuracy: 0.6993\n",
      "Epoch 73/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5767 - accuracy: 0.7079\n",
      "Epoch 74/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5758 - accuracy: 0.7047\n",
      "Epoch 75/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5753 - accuracy: 0.7063\n",
      "Epoch 76/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5784 - accuracy: 0.7079\n",
      "Epoch 77/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5747 - accuracy: 0.7124\n",
      "Epoch 78/100\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5795 - accuracy: 0.6989\n",
      "Epoch 79/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5785 - accuracy: 0.7009\n",
      "Epoch 80/100\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5757 - accuracy: 0.7079\n",
      "Epoch 81/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5756 - accuracy: 0.7121\n",
      "Epoch 82/100\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5785 - accuracy: 0.7028\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5779 - accuracy: 0.7044\n",
      "Epoch 84/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5761 - accuracy: 0.7096\n",
      "Epoch 85/100\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5770 - accuracy: 0.7070\n",
      "Epoch 86/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5816 - accuracy: 0.6970\n",
      "Epoch 87/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5770 - accuracy: 0.7034\n",
      "Epoch 88/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5774 - accuracy: 0.6999\n",
      "Epoch 89/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5785 - accuracy: 0.7050\n",
      "Epoch 90/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5755 - accuracy: 0.7038\n",
      "Epoch 91/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5755 - accuracy: 0.7076\n",
      "Epoch 92/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5746 - accuracy: 0.7102\n",
      "Epoch 93/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5764 - accuracy: 0.7005\n",
      "Epoch 94/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5759 - accuracy: 0.7057\n",
      "Epoch 95/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5773 - accuracy: 0.7073\n",
      "Epoch 96/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5780 - accuracy: 0.7050\n",
      "Epoch 97/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5752 - accuracy: 0.7060\n",
      "Epoch 98/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5833 - accuracy: 0.7041\n",
      "Epoch 99/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5802 - accuracy: 0.7057\n",
      "Epoch 100/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5784 - accuracy: 0.7012\n",
      "63/63 [==============================] - 1s 3ms/step - loss: 0.5810 - accuracy: 0.6950\n",
      "[0.5810484290122986, 0.6949999928474426]\n",
      "63/63 [==============================] - 0s 2ms/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.70      0.79      1593\n",
      "           1       0.36      0.67      0.47       407\n",
      "\n",
      "    accuracy                           0.69      2000\n",
      "   macro avg       0.63      0.68      0.63      2000\n",
      "weighted avg       0.78      0.69      0.72      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_train_batch(df2_class0, df2_class1, 4891, 6370)\n",
    "y_pred4 = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7f8fe973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2000, 2000, 2000)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred1), len(y_pred2), len(y_pred3), len(y_pred4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "90ae61dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final = y_pred1.copy()\n",
    "\n",
    "for i in range(len(y_pred1)):\n",
    "    n_ones = y_pred1[i] + y_pred2[i] + y_pred3[i] + y_pred4[i]\n",
    "    \n",
    "    if n_ones>1:\n",
    "        y_pred_final[i] = 1\n",
    "    else:\n",
    "        y_pred_final[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9e128b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.71      0.80      1593\n",
      "           1       0.40      0.73      0.51       407\n",
      "\n",
      "    accuracy                           0.72      2000\n",
      "   macro avg       0.65      0.72      0.66      2000\n",
      "weighted avg       0.81      0.72      0.74      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dfffeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
